{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Emotion Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = json.load(open('D:\\\\Github\\\\NLP-Project-24\\\\Dataset\\\\CEE_QA\\\\Predicted_Emotions\\\\BERT\\\\val_utterance_level_bert_pred.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "\n",
    "for i in range(len(val_data)):\n",
    "    conversation = val_data[i]['conversation']\n",
    "    conversation_ID = val_data[i]['conversation_ID']\n",
    "    context = \"\"\n",
    "    array = []\n",
    "    \n",
    "    for j in range(len(conversation)):\n",
    "        target = conversation[j]['text']\n",
    "        target_utterance_ID = conversation[j]['utterance_ID']\n",
    "        emotion = conversation[j]['emotion']\n",
    "        context += target + \" \"\n",
    "        if(emotion == \"neutral\"):\n",
    "            continue\n",
    "        for k in range(j+1):\n",
    "            evidence = conversation[k]['text']\n",
    "            evidence_utterance_ID = conversation[k]['utterance_ID']\n",
    "            array.append({\n",
    "                \"context\": context,\n",
    "                \"qas\":[{\n",
    "                    \"id\": f\"{conversation_ID}_{target_utterance_ID}_{evidence_utterance_ID}_{emotion}\",\n",
    "                    \"is_impossible\": True,\n",
    "                    \"question\": f\"If the target utterance is <{target}> and evidence utterance is <{evidence}> then what is the causal span from context that is relevant to the target utterance's emotion <{emotion}> ?\",\n",
    "                    \"answers\": []\n",
    "                }]\n",
    "            })\n",
    "    emotion_cause_pairs = val_data[i]['emotion-cause_pairs']\n",
    "\n",
    "    for j in range(len(emotion_cause_pairs)):\n",
    "        target_idx, cause_idx, cause = int(emotion_cause_pairs[j][0][0:str.find(emotion_cause_pairs[j][0], \"_\")]), int(emotion_cause_pairs[j][1][0:str.find(emotion_cause_pairs[j][1], \"_\")]), emotion_cause_pairs[j][1][str.find(emotion_cause_pairs[j][1], \"_\")+1:] \n",
    "        emotion = emotion_cause_pairs[j][0][str.find(emotion_cause_pairs[j][0], \"_\")+1:]\n",
    "        for k in range(len(array)):\n",
    "            if f\"{conversation_ID}_{target_idx}_{cause_idx}_{emotion}\" == array[k]['qas'][0]['id']:\n",
    "                array[k]['qas'][0]['is_impossible'] = False\n",
    "                array[k]['qas'][0]['answers'].append({\n",
    "                    \"text\": cause,\n",
    "                    \"answer_start\": array[k]['context'].find(cause)\n",
    "                })\n",
    "    val += array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(val, open('D:\\Github\\NLP-Project-24\\Dataset\\CEE_QA\\val_simple_transformers_gt.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Include Emotion Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = json.load(open('Predicted_Emotions\\\\RoBERTa\\\\val_utterance_level_roberta_pred.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "\n",
    "for i in range(len(val_data)):\n",
    "    conversation = val_data[i]['conversation']\n",
    "    conversation_ID = val_data[i]['conversation_ID']\n",
    "    context = \"\"\n",
    "    array = []\n",
    "    \n",
    "    for j in range(len(conversation)):\n",
    "        target = conversation[j]['text']\n",
    "        target_utterance_ID = conversation[j]['utterance_ID']\n",
    "        emotion = conversation[j]['emotion']\n",
    "        context += target + \" \"\n",
    "        if(emotion == \"neutral\"):\n",
    "            continue\n",
    "        for k in range(j+1):\n",
    "            evidence = conversation[k]['text']\n",
    "            evidence_utterance_ID = conversation[k]['utterance_ID']\n",
    "            array.append({\n",
    "                \"context\": context,\n",
    "                \"qas\":[{\n",
    "                    \"id\": f\"{conversation_ID}_{target_utterance_ID}_{evidence_utterance_ID}_{emotion}\",\n",
    "                    \"question\": f\"If the target utterance is <{target}> and evidence utterance is <{evidence}> then what is the causal span from context that is relevant to the target utterance's emotion <{emotion}> ?\",\n",
    "                }]\n",
    "            })\n",
    "    val += array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(val, open('Predicted_Emotions\\\\RoBERTa\\\\val_utterance_level_roberta_pred.json', 'w'), indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECPEC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
