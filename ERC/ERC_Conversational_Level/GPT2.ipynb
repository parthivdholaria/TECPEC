{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8195327,"sourceType":"datasetVersion","datasetId":4785760}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import GPT2Model, GPT2PreTrainedModel, GPT2Config\nimport pickle\nimport wandb\nfrom tqdm import tqdm\nfrom sklearn.metrics import classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:27.518661Z","iopub.execute_input":"2024-04-23T10:51:27.519057Z","iopub.status.idle":"2024-04-23T10:51:36.338149Z","shell.execute_reply.started":"2024-04-23T10:51:27.519014Z","shell.execute_reply":"2024-04-23T10:51:36.337030Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Source: https://github.com/LCS2-IIITD/Emotion-Flip-Reasoning/blob/main/Dataloaders/nlp_utils.py\nimport string\nimport nltk\nimport re\n\nnumbers = {\n    \"0\":\"zero\",\n    \"1\":\"one\",\n    \"2\":\"two\",\n    \"3\":\"three\",\n    \"4\":\"four\",\n    \"5\":\"five\",\n    \"6\":\"six\",\n    \"7\":\"seven\",\n    \"8\":\"eight\",\n    \"9\":\"nine\"\n}\n\ndef remove_puntuations(txt):\n    punct = set(string.punctuation)\n    txt = \" \".join(txt.split(\".\"))\n    txt = \" \".join(txt.split(\"!\"))\n    txt = \" \".join(txt.split(\"?\"))\n    txt = \" \".join(txt.split(\":\"))\n    txt = \" \".join(txt.split(\";\"))\n    \n    txt = \"\".join(ch for ch in txt if ch not in punct)\n    return txt\n\ndef number_to_words(txt):\n    for k in numbers.keys():\n        txt = txt.replace(k,numbers[k]+\" \")\n    return txt\n\ndef preprocess_text(text):\n    text = text.lower()\n    text = re.sub(r'_',' ',text)\n    text = number_to_words(text)\n    text = remove_puntuations(text)\n    text = ''.join([i if ord(i) < 128 else '' for i in text])\n    text = ' '.join(text.split())\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:36.340309Z","iopub.execute_input":"2024-04-23T10:51:36.340950Z","iopub.status.idle":"2024-04-23T10:51:36.932276Z","shell.execute_reply.started":"2024-04-23T10:51:36.340913Z","shell.execute_reply":"2024-04-23T10:51:36.931197Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data = json.load(open('/kaggle/input/Dataset/ERC_conversational_level/train_conversation_level.json'))\nval_data = json.load(open('/kaggle/input/Dataset/ERC_conversational_level/val_conversation_level.json'))","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:36.933584Z","iopub.execute_input":"2024-04-23T10:51:36.933873Z","iopub.status.idle":"2024-04-23T10:51:37.027323Z","shell.execute_reply.started":"2024-04-23T10:51:36.933849Z","shell.execute_reply":"2024-04-23T10:51:37.026496Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:37.029942Z","iopub.execute_input":"2024-04-23T10:51:37.030354Z","iopub.status.idle":"2024-04-23T10:51:37.097828Z","shell.execute_reply.started":"2024-04-23T10:51:37.030320Z","shell.execute_reply":"2024-04-23T10:51:37.096781Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"emotion2int = {\n    'anger': 0,\n    'joy': 1,\n    'fear': 2,\n    'disgust': 3,\n    'neutral': 4,\n    'surprise': 5,\n    'sadness': 6\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:37.099499Z","iopub.execute_input":"2024-04-23T10:51:37.099856Z","iopub.status.idle":"2024-04-23T10:51:37.106909Z","shell.execute_reply.started":"2024-04-23T10:51:37.099824Z","shell.execute_reply":"2024-04-23T10:51:37.106051Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"L = []\nfor conversation in train_data:\n    for utterance in conversation['conversation']:\n        L.append(emotion2int[utterance['emotion']])\nclass_weights=compute_class_weight(class_weight='balanced',classes=list(emotion2int.values()), y=np.array(L))","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:37.108299Z","iopub.execute_input":"2024-04-23T10:51:37.108810Z","iopub.status.idle":"2024-04-23T10:51:37.134910Z","shell.execute_reply.started":"2024-04-23T10:51:37.108779Z","shell.execute_reply":"2024-04-23T10:51:37.134009Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"utterance2vec = pickle.load(open('/kaggle/input/Dataset/Embeddings/sentence_transformer_utterance2vec_768.pkl', 'rb'))","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:37.136359Z","iopub.execute_input":"2024-04-23T10:51:37.136670Z","iopub.status.idle":"2024-04-23T10:51:38.392302Z","shell.execute_reply.started":"2024-04-23T10:51:37.136641Z","shell.execute_reply":"2024-04-23T10:51:38.391273Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"MAX_CONV_LEN = 35\n# Defined index 7 for padding\nclass ERC_Dataset_Conv_Level(Dataset):\n    def __init__(self, data, utterance2vec):\n        self.data = data\n        self.utterance2vec = utterance2vec\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        conversation = self.data[idx]['conversation']\n        texts = [utterance['text'] for utterance in conversation]\n        emotions = [emotion2int[utterance['emotion']] for utterance in conversation]\n        text_embeddings = [torch.from_numpy(self.utterance2vec[preprocess_text(text)]) for text in texts]\n                \n        if(len(text_embeddings)<MAX_CONV_LEN):\n            num_pads = MAX_CONV_LEN - len(text_embeddings)\n            attention_mask = [1]*len(text_embeddings) + [0]*num_pads\n            text_embeddings = text_embeddings + [torch.zeros(768)]*num_pads\n            emotions = emotions + [7]*num_pads # 7 is the index for padding\n        else:\n            text_embeddings = text_embeddings[len(text_embeddings)-MAX_CONV_LEN:]\n            attention_mask = [1]*MAX_CONV_LEN\n            emotions = emotions[len(emotions)-MAX_CONV_LEN:]\n\n        text_embeddings = torch.stack(text_embeddings)\n        attention_mask = torch.tensor(attention_mask)\n        emotions = torch.tensor(emotions)\n        return {\n            'text_embeddings': text_embeddings,\n            'attention_mask': attention_mask,\n            'emotions': emotions\n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:38.393512Z","iopub.execute_input":"2024-04-23T10:51:38.394259Z","iopub.status.idle":"2024-04-23T10:51:38.405616Z","shell.execute_reply.started":"2024-04-23T10:51:38.394215Z","shell.execute_reply":"2024-04-23T10:51:38.404653Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class ERC_GPT2(GPT2PreTrainedModel):\n    def __init__(self, config, weights):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        self.GPT2 = GPT2Model(config)\n        self.classifier = nn.Linear(config.n_embd, self.num_labels)\n        self.weights = weights\n        self.post_init()\n        \n\n    def forward(self, inputs_embeds, attention_mask, labels=None, device='cpu'):\n        outputs = self.GPT2(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n        outputs = outputs.last_hidden_state\n        logits, label = {}, {}\n        for b in range(outputs.size(0)):\n            logits[b] = [self.classifier(outputs[b][i]) for i in range(outputs.size(1)) if attention_mask[b][i] == 1]\n            label[b] = [labels[b][i] for i in range(outputs.size(1)) if attention_mask[b][i] == 1]\n        logits = [torch.stack(logits[b]) for b in range(outputs.size(0))]\n        label = [torch.stack(label[b]) for b in range(outputs.size(0))]\n        loss = None\n        if labels is not None:\n            loss = 0\n            for b in range(outputs.size(0)):\n                loss += nn.CrossEntropyLoss(weight=self.weights.to(device))(logits[b].to(device), label[b].to(device))\n            loss /= outputs.size(0)\n        return {\n            'loss': loss,\n            'logits': logits,\n            'labels': label   \n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:38.407116Z","iopub.execute_input":"2024-04-23T10:51:38.407948Z","iopub.status.idle":"2024-04-23T10:51:38.419442Z","shell.execute_reply.started":"2024-04-23T10:51:38.407924Z","shell.execute_reply":"2024-04-23T10:51:38.418495Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"config = GPT2Config.from_pretrained('gpt2', num_labels=7)\nmodel = ERC_GPT2.from_pretrained('gpt2', config=config, weights=torch.from_numpy(class_weights).float()).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:38.425346Z","iopub.execute_input":"2024-04-23T10:51:38.426095Z","iopub.status.idle":"2024-04-23T10:51:43.358633Z","shell.execute_reply.started":"2024-04-23T10:51:38.426064Z","shell.execute_reply":"2024-04-23T10:51:43.357526Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"535ca2a2c53345d0a8fef5a1969a35ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"711cc888b59b4939bf710c05c79640c7"}},"metadata":{}},{"name":"stderr","text":"Some weights of ERC_GPT2 were not initialized from the model checkpoint at gpt2 and are newly initialized: ['GPT2.h.0.attn.c_attn.bias', 'GPT2.h.0.attn.c_attn.weight', 'GPT2.h.0.attn.c_proj.bias', 'GPT2.h.0.attn.c_proj.weight', 'GPT2.h.0.ln_1.bias', 'GPT2.h.0.ln_1.weight', 'GPT2.h.0.ln_2.bias', 'GPT2.h.0.ln_2.weight', 'GPT2.h.0.mlp.c_fc.bias', 'GPT2.h.0.mlp.c_fc.weight', 'GPT2.h.0.mlp.c_proj.bias', 'GPT2.h.0.mlp.c_proj.weight', 'GPT2.h.1.attn.c_attn.bias', 'GPT2.h.1.attn.c_attn.weight', 'GPT2.h.1.attn.c_proj.bias', 'GPT2.h.1.attn.c_proj.weight', 'GPT2.h.1.ln_1.bias', 'GPT2.h.1.ln_1.weight', 'GPT2.h.1.ln_2.bias', 'GPT2.h.1.ln_2.weight', 'GPT2.h.1.mlp.c_fc.bias', 'GPT2.h.1.mlp.c_fc.weight', 'GPT2.h.1.mlp.c_proj.bias', 'GPT2.h.1.mlp.c_proj.weight', 'GPT2.h.10.attn.c_attn.bias', 'GPT2.h.10.attn.c_attn.weight', 'GPT2.h.10.attn.c_proj.bias', 'GPT2.h.10.attn.c_proj.weight', 'GPT2.h.10.ln_1.bias', 'GPT2.h.10.ln_1.weight', 'GPT2.h.10.ln_2.bias', 'GPT2.h.10.ln_2.weight', 'GPT2.h.10.mlp.c_fc.bias', 'GPT2.h.10.mlp.c_fc.weight', 'GPT2.h.10.mlp.c_proj.bias', 'GPT2.h.10.mlp.c_proj.weight', 'GPT2.h.11.attn.c_attn.bias', 'GPT2.h.11.attn.c_attn.weight', 'GPT2.h.11.attn.c_proj.bias', 'GPT2.h.11.attn.c_proj.weight', 'GPT2.h.11.ln_1.bias', 'GPT2.h.11.ln_1.weight', 'GPT2.h.11.ln_2.bias', 'GPT2.h.11.ln_2.weight', 'GPT2.h.11.mlp.c_fc.bias', 'GPT2.h.11.mlp.c_fc.weight', 'GPT2.h.11.mlp.c_proj.bias', 'GPT2.h.11.mlp.c_proj.weight', 'GPT2.h.2.attn.c_attn.bias', 'GPT2.h.2.attn.c_attn.weight', 'GPT2.h.2.attn.c_proj.bias', 'GPT2.h.2.attn.c_proj.weight', 'GPT2.h.2.ln_1.bias', 'GPT2.h.2.ln_1.weight', 'GPT2.h.2.ln_2.bias', 'GPT2.h.2.ln_2.weight', 'GPT2.h.2.mlp.c_fc.bias', 'GPT2.h.2.mlp.c_fc.weight', 'GPT2.h.2.mlp.c_proj.bias', 'GPT2.h.2.mlp.c_proj.weight', 'GPT2.h.3.attn.c_attn.bias', 'GPT2.h.3.attn.c_attn.weight', 'GPT2.h.3.attn.c_proj.bias', 'GPT2.h.3.attn.c_proj.weight', 'GPT2.h.3.ln_1.bias', 'GPT2.h.3.ln_1.weight', 'GPT2.h.3.ln_2.bias', 'GPT2.h.3.ln_2.weight', 'GPT2.h.3.mlp.c_fc.bias', 'GPT2.h.3.mlp.c_fc.weight', 'GPT2.h.3.mlp.c_proj.bias', 'GPT2.h.3.mlp.c_proj.weight', 'GPT2.h.4.attn.c_attn.bias', 'GPT2.h.4.attn.c_attn.weight', 'GPT2.h.4.attn.c_proj.bias', 'GPT2.h.4.attn.c_proj.weight', 'GPT2.h.4.ln_1.bias', 'GPT2.h.4.ln_1.weight', 'GPT2.h.4.ln_2.bias', 'GPT2.h.4.ln_2.weight', 'GPT2.h.4.mlp.c_fc.bias', 'GPT2.h.4.mlp.c_fc.weight', 'GPT2.h.4.mlp.c_proj.bias', 'GPT2.h.4.mlp.c_proj.weight', 'GPT2.h.5.attn.c_attn.bias', 'GPT2.h.5.attn.c_attn.weight', 'GPT2.h.5.attn.c_proj.bias', 'GPT2.h.5.attn.c_proj.weight', 'GPT2.h.5.ln_1.bias', 'GPT2.h.5.ln_1.weight', 'GPT2.h.5.ln_2.bias', 'GPT2.h.5.ln_2.weight', 'GPT2.h.5.mlp.c_fc.bias', 'GPT2.h.5.mlp.c_fc.weight', 'GPT2.h.5.mlp.c_proj.bias', 'GPT2.h.5.mlp.c_proj.weight', 'GPT2.h.6.attn.c_attn.bias', 'GPT2.h.6.attn.c_attn.weight', 'GPT2.h.6.attn.c_proj.bias', 'GPT2.h.6.attn.c_proj.weight', 'GPT2.h.6.ln_1.bias', 'GPT2.h.6.ln_1.weight', 'GPT2.h.6.ln_2.bias', 'GPT2.h.6.ln_2.weight', 'GPT2.h.6.mlp.c_fc.bias', 'GPT2.h.6.mlp.c_fc.weight', 'GPT2.h.6.mlp.c_proj.bias', 'GPT2.h.6.mlp.c_proj.weight', 'GPT2.h.7.attn.c_attn.bias', 'GPT2.h.7.attn.c_attn.weight', 'GPT2.h.7.attn.c_proj.bias', 'GPT2.h.7.attn.c_proj.weight', 'GPT2.h.7.ln_1.bias', 'GPT2.h.7.ln_1.weight', 'GPT2.h.7.ln_2.bias', 'GPT2.h.7.ln_2.weight', 'GPT2.h.7.mlp.c_fc.bias', 'GPT2.h.7.mlp.c_fc.weight', 'GPT2.h.7.mlp.c_proj.bias', 'GPT2.h.7.mlp.c_proj.weight', 'GPT2.h.8.attn.c_attn.bias', 'GPT2.h.8.attn.c_attn.weight', 'GPT2.h.8.attn.c_proj.bias', 'GPT2.h.8.attn.c_proj.weight', 'GPT2.h.8.ln_1.bias', 'GPT2.h.8.ln_1.weight', 'GPT2.h.8.ln_2.bias', 'GPT2.h.8.ln_2.weight', 'GPT2.h.8.mlp.c_fc.bias', 'GPT2.h.8.mlp.c_fc.weight', 'GPT2.h.8.mlp.c_proj.bias', 'GPT2.h.8.mlp.c_proj.weight', 'GPT2.h.9.attn.c_attn.bias', 'GPT2.h.9.attn.c_attn.weight', 'GPT2.h.9.attn.c_proj.bias', 'GPT2.h.9.attn.c_proj.weight', 'GPT2.h.9.ln_1.bias', 'GPT2.h.9.ln_1.weight', 'GPT2.h.9.ln_2.bias', 'GPT2.h.9.ln_2.weight', 'GPT2.h.9.mlp.c_fc.bias', 'GPT2.h.9.mlp.c_fc.weight', 'GPT2.h.9.mlp.c_proj.bias', 'GPT2.h.9.mlp.c_proj.weight', 'GPT2.ln_f.bias', 'GPT2.ln_f.weight', 'GPT2.wpe.weight', 'GPT2.wte.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = ERC_Dataset_Conv_Level(train_data, utterance2vec)\nval_dataset = ERC_Dataset_Conv_Level(val_data, utterance2vec)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:43.359924Z","iopub.execute_input":"2024-04-23T10:51:43.360718Z","iopub.status.idle":"2024-04-23T10:51:43.366273Z","shell.execute_reply.started":"2024-04-23T10:51:43.360673Z","shell.execute_reply":"2024-04-23T10:51:43.365298Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"epochs = 100\noptimizer = AdamW(model.parameters(), lr=1e-7)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:43.367784Z","iopub.execute_input":"2024-04-23T10:51:43.368151Z","iopub.status.idle":"2024-04-23T10:51:43.376783Z","shell.execute_reply.started":"2024-04-23T10:51:43.368119Z","shell.execute_reply":"2024-04-23T10:51:43.375934Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_login_key\")\nwandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:43.378115Z","iopub.execute_input":"2024-04-23T10:51:43.378476Z","iopub.status.idle":"2024-04-23T10:51:45.683755Z","shell.execute_reply.started":"2024-04-23T10:51:43.378447Z","shell.execute_reply":"2024-04-23T10:51:45.682739Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"wandb.init(project='TECPEC', name='GPT2_Conv_Level', config={\n    'Embedding': 'Sentence-Transformer',\n    'Level': 'Conversation Level',\n    'Epochs': epochs,\n    'Optimizer': 'AdamW',\n    'Learning Rate': 1e-7,\n    'Batch Size': 16\n})","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:51:45.684929Z","iopub.execute_input":"2024-04-23T10:51:45.685481Z","iopub.status.idle":"2024-04-23T10:52:02.767853Z","shell.execute_reply.started":"2024-04-23T10:51:45.685454Z","shell.execute_reply":"2024-04-23T10:52:02.766943Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshreyas21563\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240423_105145-8gzhm64z</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shreyas21563/TECPEC/runs/8gzhm64z' target=\"_blank\">GPT2_Conv_Level</a></strong> to <a href='https://wandb.ai/shreyas21563/TECPEC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shreyas21563/TECPEC' target=\"_blank\">https://wandb.ai/shreyas21563/TECPEC</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shreyas21563/TECPEC/runs/8gzhm64z' target=\"_blank\">https://wandb.ai/shreyas21563/TECPEC/runs/8gzhm64z</a>"},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shreyas21563/TECPEC/runs/8gzhm64z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x797e31165660>"},"metadata":{}}]},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    train_pred, train_true, train_loss = [], [], 0.0\n    for batch in tqdm(train_loader):\n        optimizer.zero_grad()\n        text_embeddings, attention_mask, emotions = batch['text_embeddings'].to(device), batch['attention_mask'].to(device), batch['emotions'].to(device)\n        outputs = model(inputs_embeds=text_embeddings, attention_mask=attention_mask, labels=emotions, device=device)\n        loss = outputs['loss']\n        loss.backward()\n        optimizer.step()\n        for b in range(len(outputs['logits'])):\n            train_pred.extend(torch.argmax(outputs['logits'][b], 1).tolist())\n            train_true.extend(outputs['labels'][b].tolist())\n        train_loss += loss.item()\n    train_loss /= len(train_loader) \n    model.eval()\n    val_pred, val_true, val_loss = [], [], 0.0\n    with torch.no_grad():\n        for batch in tqdm(val_loader):\n            text_embeddings, attention_mask, emotions = batch['text_embeddings'].to(device), batch['attention_mask'].to(device), batch['emotions'].to(device)\n            outputs = model(inputs_embeds=text_embeddings, attention_mask=attention_mask, labels=emotions)\n            loss = outputs['loss']\n            for b in range(len(outputs['logits'])):\n                val_pred.extend(torch.argmax(outputs['logits'][b], 1).tolist())\n                val_true.extend(outputs['labels'][b].tolist())\n            val_loss += loss.item()\n            \n    val_loss /= len(val_loader)\n    train_report = classification_report(train_true, train_pred, target_names=emotion2int.keys(), zero_division=0)\n    val_report = classification_report(val_true, val_pred, target_names=emotion2int.keys(), zero_division=0)\n\n    train_report_dict = classification_report(train_true, train_pred, target_names=emotion2int.keys(), output_dict=True, zero_division=0)\n    val_report_dict = classification_report(val_true, val_pred, target_names=emotion2int.keys(), output_dict=True, zero_division=0)\n    wandb.log({\n        'train_loss': train_loss,\n        'val_loss': val_loss,\n        'train_accuracy': train_report_dict['accuracy'],\n        'val_accuracy': val_report_dict['accuracy'],\n        'Macro train_f1': train_report_dict['macro avg']['f1-score'],\n        'Macro val_f1': val_report_dict['macro avg']['f1-score'],\n        'Weighted train_f1': train_report_dict['weighted avg']['f1-score'],\n        'Weighted val_f1': val_report_dict['weighted avg']['f1-score'],\n    })\n    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n    print(f\"Train Report: \\n{train_report}\")\n    print(f\"Val Report: \\n{val_report}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T10:52:02.770277Z","iopub.execute_input":"2024-04-23T10:52:02.770753Z","iopub.status.idle":"2024-04-23T11:18:43.690492Z","shell.execute_reply.started":"2024-04-23T10:52:02.770705Z","shell.execute_reply":"2024-04-23T11:18:43.689288Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  4.89it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Train Loss: 2.0072664526792674, Val Loss: 1.9618019527859158\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.11      0.09      0.09      1423\n         joy       0.17      0.21      0.19      2047\n        fear       0.02      0.04      0.03       336\n     disgust       0.02      0.02      0.02       372\n     neutral       0.43      0.33      0.37      5299\n    surprise       0.14      0.18      0.15      1656\n     sadness       0.07      0.08      0.07      1011\n\n    accuracy                           0.22     12144\n   macro avg       0.14      0.13      0.13     12144\nweighted avg       0.25      0.22      0.23     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.10      0.05      0.07       192\n         joy       0.20      0.29      0.24       254\n        fear       0.10      0.03      0.04        37\n     disgust       0.00      0.00      0.00        42\n     neutral       0.42      0.43      0.43       630\n    surprise       0.09      0.08      0.09       184\n     sadness       0.05      0.05      0.05       136\n\n    accuracy                           0.26      1475\n   macro avg       0.14      0.13      0.13      1475\nweighted avg       0.24      0.26      0.25      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:14<00:00,  5.27it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Train Loss: 1.9606205973869715, Val Loss: 1.9370386865403917\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.11      0.08      0.09      1423\n         joy       0.18      0.28      0.22      2047\n        fear       0.04      0.02      0.03       336\n     disgust       0.03      0.02      0.02       372\n     neutral       0.44      0.39      0.41      5299\n    surprise       0.15      0.18      0.16      1656\n     sadness       0.09      0.08      0.09      1011\n\n    accuracy                           0.26     12144\n   macro avg       0.15      0.15      0.15     12144\nweighted avg       0.27      0.26      0.26     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.14      0.09      0.11       192\n         joy       0.22      0.29      0.25       254\n        fear       0.20      0.03      0.05        37\n     disgust       0.00      0.00      0.00        42\n     neutral       0.41      0.40      0.40       630\n    surprise       0.11      0.14      0.12       184\n     sadness       0.07      0.07      0.07       136\n\n    accuracy                           0.26      1475\n   macro avg       0.16      0.15      0.14      1475\nweighted avg       0.26      0.26      0.25      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:14<00:00,  5.27it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Train Loss: 1.9440334485127375, Val Loss: 1.916216320461697\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.13      0.10      0.11      1423\n         joy       0.19      0.27      0.23      2047\n        fear       0.02      0.01      0.01       336\n     disgust       0.03      0.02      0.02       372\n     neutral       0.44      0.38      0.41      5299\n    surprise       0.14      0.18      0.16      1656\n     sadness       0.08      0.08      0.08      1011\n\n    accuracy                           0.26     12144\n   macro avg       0.15      0.15      0.15     12144\nweighted avg       0.27      0.26      0.26     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.17      0.11      0.13       192\n         joy       0.23      0.30      0.26       254\n        fear       0.17      0.03      0.05        37\n     disgust       0.00      0.00      0.00        42\n     neutral       0.44      0.46      0.45       630\n    surprise       0.14      0.18      0.16       184\n     sadness       0.08      0.06      0.07       136\n\n    accuracy                           0.29      1475\n   macro avg       0.18      0.16      0.16      1475\nweighted avg       0.28      0.29      0.28      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Train Loss: 1.926873994179261, Val Loss: 1.8970050944222345\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.13      0.09      0.11      1423\n         joy       0.20      0.28      0.23      2047\n        fear       0.03      0.01      0.02       336\n     disgust       0.03      0.03      0.03       372\n     neutral       0.46      0.41      0.43      5299\n    surprise       0.16      0.22      0.19      1656\n     sadness       0.10      0.08      0.09      1011\n\n    accuracy                           0.27     12144\n   macro avg       0.16      0.16      0.16     12144\nweighted avg       0.28      0.27      0.27     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.20      0.13      0.16       192\n         joy       0.25      0.31      0.28       254\n        fear       0.12      0.03      0.04        37\n     disgust       0.00      0.00      0.00        42\n     neutral       0.43      0.42      0.42       630\n    surprise       0.12      0.14      0.13       184\n     sadness       0.10      0.12      0.11       136\n\n    accuracy                           0.28      1475\n   macro avg       0.17      0.16      0.16      1475\nweighted avg       0.28      0.28      0.28      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Train Loss: 1.8982677138768709, Val Loss: 1.8804008695814345\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.14      0.09      0.11      1423\n         joy       0.22      0.31      0.25      2047\n        fear       0.05      0.02      0.03       336\n     disgust       0.02      0.02      0.02       372\n     neutral       0.45      0.40      0.43      5299\n    surprise       0.17      0.24      0.20      1656\n     sadness       0.11      0.10      0.11      1011\n\n    accuracy                           0.28     12144\n   macro avg       0.17      0.17      0.16     12144\nweighted avg       0.29      0.28      0.28     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.21      0.16      0.18       192\n         joy       0.29      0.36      0.32       254\n        fear       0.09      0.03      0.04        37\n     disgust       0.00      0.00      0.00        42\n     neutral       0.44      0.43      0.44       630\n    surprise       0.17      0.21      0.19       184\n     sadness       0.11      0.10      0.11       136\n\n    accuracy                           0.30      1475\n   macro avg       0.19      0.18      0.18      1475\nweighted avg       0.30      0.30      0.30      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Train Loss: 1.8838509321212769, Val Loss: 1.8637994130452473\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.16      0.15      0.15      1423\n         joy       0.24      0.29      0.26      2047\n        fear       0.06      0.02      0.03       336\n     disgust       0.03      0.02      0.03       372\n     neutral       0.46      0.41      0.43      5299\n    surprise       0.18      0.24      0.21      1656\n     sadness       0.11      0.11      0.11      1011\n\n    accuracy                           0.29     12144\n   macro avg       0.18      0.18      0.18     12144\nweighted avg       0.30      0.29      0.29     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.20      0.18      0.19       192\n         joy       0.31      0.43      0.36       254\n        fear       0.12      0.05      0.08        37\n     disgust       0.00      0.00      0.00        42\n     neutral       0.45      0.35      0.40       630\n    surprise       0.19      0.24      0.22       184\n     sadness       0.12      0.16      0.14       136\n\n    accuracy                           0.29      1475\n   macro avg       0.20      0.20      0.20      1475\nweighted avg       0.31      0.29      0.30      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.19it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 7, Train Loss: 1.865354958253029, Val Loss: 1.852524095111423\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.18      0.14      0.16      1423\n         joy       0.24      0.32      0.27      2047\n        fear       0.05      0.03      0.04       336\n     disgust       0.04      0.04      0.04       372\n     neutral       0.47      0.41      0.44      5299\n    surprise       0.20      0.25      0.22      1656\n     sadness       0.13      0.14      0.13      1011\n\n    accuracy                           0.29     12144\n   macro avg       0.19      0.19      0.19     12144\nweighted avg       0.31      0.29      0.30     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.22      0.17      0.19       192\n         joy       0.31      0.46      0.37       254\n        fear       0.14      0.05      0.08        37\n     disgust       0.00      0.00      0.00        42\n     neutral       0.47      0.35      0.40       630\n    surprise       0.19      0.27      0.22       184\n     sadness       0.13      0.17      0.15       136\n\n    accuracy                           0.30      1475\n   macro avg       0.21      0.21      0.20      1475\nweighted avg       0.32      0.30      0.30      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 8, Train Loss: 1.8590548221881573, Val Loss: 1.8395708666907415\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.20      0.12      0.15      1423\n         joy       0.24      0.36      0.29      2047\n        fear       0.06      0.04      0.05       336\n     disgust       0.07      0.05      0.06       372\n     neutral       0.48      0.38      0.42      5299\n    surprise       0.20      0.29      0.23      1656\n     sadness       0.14      0.14      0.14      1011\n\n    accuracy                           0.29     12144\n   macro avg       0.20      0.20      0.19     12144\nweighted avg       0.31      0.29      0.30     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.26      0.25       192\n         joy       0.34      0.47      0.40       254\n        fear       0.13      0.05      0.08        37\n     disgust       0.00      0.00      0.00        42\n     neutral       0.47      0.35      0.40       630\n    surprise       0.20      0.28      0.23       184\n     sadness       0.16      0.17      0.17       136\n\n    accuracy                           0.32      1475\n   macro avg       0.22      0.23      0.22      1475\nweighted avg       0.34      0.32      0.32      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 9, Train Loss: 1.828894127637912, Val Loss: 1.8293051719665527\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.19      0.17      0.18      1423\n         joy       0.27      0.34      0.30      2047\n        fear       0.07      0.04      0.05       336\n     disgust       0.05      0.04      0.05       372\n     neutral       0.48      0.42      0.45      5299\n    surprise       0.22      0.31      0.26      1656\n     sadness       0.15      0.13      0.14      1011\n\n    accuracy                           0.32     12144\n   macro avg       0.21      0.21      0.20     12144\nweighted avg       0.33      0.32      0.32     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.27      0.25       192\n         joy       0.36      0.50      0.42       254\n        fear       0.11      0.05      0.07        37\n     disgust       0.02      0.02      0.02        42\n     neutral       0.49      0.36      0.41       630\n    surprise       0.22      0.27      0.24       184\n     sadness       0.15      0.18      0.16       136\n\n    accuracy                           0.33      1475\n   macro avg       0.23      0.24      0.23      1475\nweighted avg       0.35      0.33      0.33      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.09it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10, Train Loss: 1.8124569792013903, Val Loss: 1.8201252619425456\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.21      0.17      0.19      1423\n         joy       0.27      0.39      0.32      2047\n        fear       0.05      0.03      0.04       336\n     disgust       0.04      0.04      0.04       372\n     neutral       0.50      0.42      0.46      5299\n    surprise       0.24      0.29      0.26      1656\n     sadness       0.14      0.15      0.14      1011\n\n    accuracy                           0.32     12144\n   macro avg       0.21      0.21      0.21     12144\nweighted avg       0.33      0.32      0.33     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.27      0.25       192\n         joy       0.37      0.51      0.43       254\n        fear       0.17      0.08      0.11        37\n     disgust       0.04      0.05      0.04        42\n     neutral       0.49      0.33      0.39       630\n    surprise       0.21      0.30      0.25       184\n     sadness       0.15      0.17      0.16       136\n\n    accuracy                           0.32      1475\n   macro avg       0.24      0.24      0.23      1475\nweighted avg       0.35      0.32      0.32      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 11, Train Loss: 1.8021327532254732, Val Loss: 1.811026692390442\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.20      0.19      0.19      1423\n         joy       0.29      0.40      0.34      2047\n        fear       0.05      0.03      0.04       336\n     disgust       0.08      0.06      0.07       372\n     neutral       0.50      0.39      0.44      5299\n    surprise       0.23      0.30      0.26      1656\n     sadness       0.16      0.18      0.17      1011\n\n    accuracy                           0.32     12144\n   macro avg       0.21      0.22      0.21     12144\nweighted avg       0.34      0.32      0.32     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.24      0.24       192\n         joy       0.37      0.52      0.43       254\n        fear       0.14      0.08      0.10        37\n     disgust       0.02      0.02      0.02        42\n     neutral       0.49      0.33      0.40       630\n    surprise       0.22      0.31      0.26       184\n     sadness       0.14      0.18      0.16       136\n\n    accuracy                           0.32      1475\n   macro avg       0.23      0.24      0.23      1475\nweighted avg       0.35      0.32      0.33      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12, Train Loss: 1.7948527274987636, Val Loss: 1.802613655726115\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.21      0.20      0.21      1423\n         joy       0.29      0.40      0.33      2047\n        fear       0.06      0.04      0.05       336\n     disgust       0.07      0.07      0.07       372\n     neutral       0.51      0.38      0.44      5299\n    surprise       0.23      0.31      0.26      1656\n     sadness       0.18      0.20      0.19      1011\n\n    accuracy                           0.32     12144\n   macro avg       0.22      0.23      0.22     12144\nweighted avg       0.34      0.32      0.33     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.29      0.27       192\n         joy       0.41      0.50      0.45       254\n        fear       0.13      0.08      0.10        37\n     disgust       0.03      0.02      0.03        42\n     neutral       0.49      0.37      0.42       630\n    surprise       0.22      0.29      0.25       184\n     sadness       0.16      0.20      0.17       136\n\n    accuracy                           0.34      1475\n   macro avg       0.24      0.25      0.24      1475\nweighted avg       0.36      0.34      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.12it/s]\n100%|██████████| 9/9 [00:00<00:00, 11.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 13, Train Loss: 1.7834386856128008, Val Loss: 1.7938831514782376\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.22      0.20      0.21      1423\n         joy       0.30      0.39      0.34      2047\n        fear       0.06      0.05      0.05       336\n     disgust       0.07      0.07      0.07       372\n     neutral       0.51      0.39      0.44      5299\n    surprise       0.25      0.33      0.28      1656\n     sadness       0.17      0.20      0.18      1011\n\n    accuracy                           0.33     12144\n   macro avg       0.22      0.23      0.23     12144\nweighted avg       0.35      0.33      0.33     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.27      0.26       192\n         joy       0.38      0.52      0.44       254\n        fear       0.10      0.08      0.09        37\n     disgust       0.04      0.05      0.04        42\n     neutral       0.49      0.35      0.41       630\n    surprise       0.24      0.27      0.25       184\n     sadness       0.17      0.21      0.18       136\n\n    accuracy                           0.33      1475\n   macro avg       0.24      0.25      0.24      1475\nweighted avg       0.36      0.33      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 14, Train Loss: 1.7629460875804608, Val Loss: 1.7869868410958185\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.23      0.21      0.22      1423\n         joy       0.29      0.40      0.34      2047\n        fear       0.08      0.07      0.08       336\n     disgust       0.06      0.07      0.07       372\n     neutral       0.51      0.39      0.44      5299\n    surprise       0.24      0.31      0.27      1656\n     sadness       0.17      0.19      0.18      1011\n\n    accuracy                           0.32     12144\n   macro avg       0.23      0.23      0.23     12144\nweighted avg       0.35      0.32      0.33     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.30      0.27       192\n         joy       0.39      0.52      0.45       254\n        fear       0.14      0.08      0.10        37\n     disgust       0.05      0.05      0.05        42\n     neutral       0.49      0.36      0.41       630\n    surprise       0.24      0.28      0.26       184\n     sadness       0.17      0.21      0.19       136\n\n    accuracy                           0.34      1475\n   macro avg       0.25      0.26      0.25      1475\nweighted avg       0.36      0.34      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 15, Train Loss: 1.755541552335788, Val Loss: 1.7799967527389526\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.22      0.23      0.23      1423\n         joy       0.31      0.40      0.35      2047\n        fear       0.09      0.07      0.08       336\n     disgust       0.09      0.09      0.09       372\n     neutral       0.51      0.39      0.45      5299\n    surprise       0.26      0.35      0.30      1656\n     sadness       0.17      0.20      0.19      1011\n\n    accuracy                           0.33     12144\n   macro avg       0.24      0.25      0.24     12144\nweighted avg       0.36      0.33      0.34     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.29      0.27       192\n         joy       0.38      0.52      0.44       254\n        fear       0.14      0.08      0.10        37\n     disgust       0.07      0.07      0.07        42\n     neutral       0.50      0.35      0.41       630\n    surprise       0.25      0.30      0.27       184\n     sadness       0.18      0.23      0.20       136\n\n    accuracy                           0.34      1475\n   macro avg       0.25      0.26      0.25      1475\nweighted avg       0.36      0.34      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 16, Train Loss: 1.7508918322049654, Val Loss: 1.7745713127983942\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.22      0.25      0.24      1423\n         joy       0.32      0.43      0.37      2047\n        fear       0.10      0.07      0.08       336\n     disgust       0.06      0.06      0.06       372\n     neutral       0.52      0.40      0.46      5299\n    surprise       0.28      0.33      0.31      1656\n     sadness       0.19      0.23      0.21      1011\n\n    accuracy                           0.35     12144\n   macro avg       0.24      0.25      0.25     12144\nweighted avg       0.37      0.35      0.35     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.26      0.24       192\n         joy       0.37      0.55      0.44       254\n        fear       0.08      0.08      0.08        37\n     disgust       0.07      0.07      0.07        42\n     neutral       0.50      0.29      0.37       630\n    surprise       0.24      0.34      0.29       184\n     sadness       0.17      0.24      0.20       136\n\n    accuracy                           0.32      1475\n   macro avg       0.24      0.26      0.24      1475\nweighted avg       0.36      0.32      0.32      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 17, Train Loss: 1.7328247320957673, Val Loss: 1.7679702308442857\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.22      0.20      0.21      1423\n         joy       0.32      0.41      0.36      2047\n        fear       0.07      0.07      0.07       336\n     disgust       0.07      0.08      0.07       372\n     neutral       0.53      0.40      0.46      5299\n    surprise       0.26      0.36      0.30      1656\n     sadness       0.20      0.23      0.22      1011\n\n    accuracy                           0.34     12144\n   macro avg       0.24      0.25      0.24     12144\nweighted avg       0.37      0.34      0.35     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.23      0.33      0.27       192\n         joy       0.38      0.52      0.44       254\n        fear       0.12      0.08      0.10        37\n     disgust       0.06      0.07      0.06        42\n     neutral       0.50      0.33      0.40       630\n    surprise       0.26      0.30      0.28       184\n     sadness       0.19      0.23      0.21       136\n\n    accuracy                           0.33      1475\n   macro avg       0.25      0.27      0.25      1475\nweighted avg       0.37      0.33      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 18, Train Loss: 1.7331942640818083, Val Loss: 1.7637045913272433\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.23      0.24      0.23      1423\n         joy       0.34      0.44      0.38      2047\n        fear       0.10      0.11      0.10       336\n     disgust       0.09      0.10      0.10       372\n     neutral       0.54      0.40      0.45      5299\n    surprise       0.29      0.35      0.32      1656\n     sadness       0.22      0.28      0.24      1011\n\n    accuracy                           0.35     12144\n   macro avg       0.26      0.27      0.26     12144\nweighted avg       0.38      0.35      0.36     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.27      0.26       192\n         joy       0.37      0.55      0.44       254\n        fear       0.10      0.08      0.09        37\n     disgust       0.06      0.07      0.07        42\n     neutral       0.51      0.31      0.39       630\n    surprise       0.27      0.37      0.31       184\n     sadness       0.18      0.23      0.20       136\n\n    accuracy                           0.33      1475\n   macro avg       0.25      0.27      0.25      1475\nweighted avg       0.37      0.33      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.03it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 19, Train Loss: 1.717697615806873, Val Loss: 1.757633023791843\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.25      0.25      1423\n         joy       0.32      0.43      0.37      2047\n        fear       0.10      0.10      0.10       336\n     disgust       0.09      0.11      0.10       372\n     neutral       0.54      0.39      0.45      5299\n    surprise       0.27      0.35      0.31      1656\n     sadness       0.22      0.26      0.24      1011\n\n    accuracy                           0.35     12144\n   macro avg       0.26      0.27      0.26     12144\nweighted avg       0.38      0.35      0.36     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.28      0.26       192\n         joy       0.39      0.54      0.45       254\n        fear       0.07      0.08      0.08        37\n     disgust       0.05      0.07      0.06        42\n     neutral       0.50      0.32      0.39       630\n    surprise       0.28      0.36      0.32       184\n     sadness       0.19      0.24      0.21       136\n\n    accuracy                           0.34      1475\n   macro avg       0.25      0.27      0.25      1475\nweighted avg       0.37      0.34      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.07it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 20, Train Loss: 1.7073311362511072, Val Loss: 1.752248724301656\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.24      0.24      1423\n         joy       0.35      0.45      0.39      2047\n        fear       0.11      0.11      0.11       336\n     disgust       0.09      0.09      0.09       372\n     neutral       0.54      0.41      0.46      5299\n    surprise       0.28      0.37      0.32      1656\n     sadness       0.23      0.28      0.25      1011\n\n    accuracy                           0.36     12144\n   macro avg       0.26      0.28      0.27     12144\nweighted avg       0.39      0.36      0.37     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.23      0.28      0.26       192\n         joy       0.39      0.54      0.45       254\n        fear       0.06      0.08      0.07        37\n     disgust       0.05      0.07      0.06        42\n     neutral       0.49      0.31      0.38       630\n    surprise       0.28      0.35      0.31       184\n     sadness       0.20      0.24      0.21       136\n\n    accuracy                           0.33      1475\n   macro avg       0.24      0.27      0.25      1475\nweighted avg       0.36      0.33      0.33      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 21, Train Loss: 1.6970714514072125, Val Loss: 1.748496413230896\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.27      0.26      1423\n         joy       0.34      0.44      0.38      2047\n        fear       0.12      0.12      0.12       336\n     disgust       0.11      0.17      0.13       372\n     neutral       0.54      0.39      0.46      5299\n    surprise       0.29      0.36      0.32      1656\n     sadness       0.22      0.27      0.24      1011\n\n    accuracy                           0.36     12144\n   macro avg       0.27      0.29      0.27     12144\nweighted avg       0.39      0.36      0.37     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.27      0.25       192\n         joy       0.38      0.54      0.45       254\n        fear       0.07      0.08      0.07        37\n     disgust       0.04      0.07      0.05        42\n     neutral       0.50      0.30      0.38       630\n    surprise       0.29      0.35      0.32       184\n     sadness       0.19      0.26      0.22       136\n\n    accuracy                           0.33      1475\n   macro avg       0.25      0.27      0.25      1475\nweighted avg       0.37      0.33      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 22, Train Loss: 1.6885627171932123, Val Loss: 1.7452586889266968\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.27      0.26      1423\n         joy       0.35      0.45      0.39      2047\n        fear       0.10      0.12      0.11       336\n     disgust       0.08      0.09      0.09       372\n     neutral       0.55      0.38      0.45      5299\n    surprise       0.29      0.37      0.33      1656\n     sadness       0.22      0.31      0.26      1011\n\n    accuracy                           0.35     12144\n   macro avg       0.26      0.28      0.27     12144\nweighted avg       0.39      0.35      0.36     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.23      0.22      0.23       192\n         joy       0.40      0.53      0.46       254\n        fear       0.05      0.08      0.07        37\n     disgust       0.05      0.10      0.07        42\n     neutral       0.51      0.33      0.40       630\n    surprise       0.30      0.38      0.33       184\n     sadness       0.22      0.31      0.25       136\n\n    accuracy                           0.34      1475\n   macro avg       0.25      0.28      0.26      1475\nweighted avg       0.38      0.34      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 23, Train Loss: 1.6756841601469579, Val Loss: 1.7409399880303278\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.21      0.23      1423\n         joy       0.35      0.45      0.39      2047\n        fear       0.10      0.12      0.11       336\n     disgust       0.14      0.15      0.14       372\n     neutral       0.55      0.41      0.47      5299\n    surprise       0.30      0.41      0.35      1656\n     sadness       0.23      0.29      0.26      1011\n\n    accuracy                           0.37     12144\n   macro avg       0.27      0.29      0.28     12144\nweighted avg       0.40      0.37      0.37     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.23      0.27      0.25       192\n         joy       0.41      0.52      0.46       254\n        fear       0.06      0.08      0.07        37\n     disgust       0.04      0.07      0.05        42\n     neutral       0.51      0.32      0.39       630\n    surprise       0.28      0.36      0.32       184\n     sadness       0.21      0.25      0.23       136\n\n    accuracy                           0.33      1475\n   macro avg       0.25      0.27      0.25      1475\nweighted avg       0.37      0.33      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.06it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 24, Train Loss: 1.6761778103999603, Val Loss: 1.7384119431177776\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.30      0.28      1423\n         joy       0.35      0.46      0.40      2047\n        fear       0.09      0.13      0.11       336\n     disgust       0.11      0.14      0.12       372\n     neutral       0.56      0.39      0.46      5299\n    surprise       0.31      0.35      0.33      1656\n     sadness       0.24      0.32      0.27      1011\n\n    accuracy                           0.37     12144\n   macro avg       0.28      0.30      0.28     12144\nweighted avg       0.40      0.37      0.38     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.27      0.25       192\n         joy       0.41      0.54      0.47       254\n        fear       0.07      0.08      0.08        37\n     disgust       0.04      0.07      0.05        42\n     neutral       0.51      0.32      0.39       630\n    surprise       0.29      0.40      0.34       184\n     sadness       0.22      0.25      0.23       136\n\n    accuracy                           0.34      1475\n   macro avg       0.25      0.28      0.26      1475\nweighted avg       0.38      0.34      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.05it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 25, Train Loss: 1.6620671198918269, Val Loss: 1.7336663272645738\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.26      0.26      1423\n         joy       0.36      0.45      0.40      2047\n        fear       0.11      0.12      0.11       336\n     disgust       0.10      0.12      0.11       372\n     neutral       0.56      0.39      0.46      5299\n    surprise       0.31      0.43      0.36      1656\n     sadness       0.23      0.32      0.27      1011\n\n    accuracy                           0.37     12144\n   macro avg       0.28      0.30      0.28     12144\nweighted avg       0.41      0.37      0.38     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.28      0.26       192\n         joy       0.40      0.55      0.46       254\n        fear       0.07      0.08      0.07        37\n     disgust       0.04      0.07      0.05        42\n     neutral       0.52      0.32      0.40       630\n    surprise       0.31      0.39      0.34       184\n     sadness       0.23      0.26      0.24       136\n\n    accuracy                           0.35      1475\n   macro avg       0.26      0.28      0.26      1475\nweighted avg       0.39      0.35      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 26, Train Loss: 1.655618809736692, Val Loss: 1.7294299470053778\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.29      0.27      1423\n         joy       0.35      0.46      0.40      2047\n        fear       0.12      0.14      0.13       336\n     disgust       0.11      0.16      0.13       372\n     neutral       0.58      0.40      0.47      5299\n    surprise       0.30      0.38      0.34      1656\n     sadness       0.26      0.30      0.28      1011\n\n    accuracy                           0.37     12144\n   macro avg       0.28      0.30      0.29     12144\nweighted avg       0.41      0.37      0.38     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.25      0.24       192\n         joy       0.40      0.55      0.46       254\n        fear       0.05      0.08      0.06        37\n     disgust       0.04      0.07      0.05        42\n     neutral       0.51      0.31      0.39       630\n    surprise       0.31      0.38      0.34       184\n     sadness       0.23      0.31      0.27       136\n\n    accuracy                           0.34      1475\n   macro avg       0.25      0.28      0.26      1475\nweighted avg       0.38      0.34      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.11it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 27, Train Loss: 1.6436985242061126, Val Loss: 1.7287981907526653\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.27      0.27      1423\n         joy       0.36      0.47      0.40      2047\n        fear       0.12      0.18      0.15       336\n     disgust       0.11      0.17      0.13       372\n     neutral       0.56      0.40      0.46      5299\n    surprise       0.32      0.37      0.34      1656\n     sadness       0.26      0.33      0.29      1011\n\n    accuracy                           0.37     12144\n   macro avg       0.28      0.31      0.29     12144\nweighted avg       0.41      0.37      0.38     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.26      0.25       192\n         joy       0.40      0.54      0.46       254\n        fear       0.05      0.08      0.06        37\n     disgust       0.04      0.07      0.05        42\n     neutral       0.51      0.31      0.39       630\n    surprise       0.30      0.40      0.35       184\n     sadness       0.24      0.29      0.26       136\n\n    accuracy                           0.34      1475\n   macro avg       0.26      0.28      0.26      1475\nweighted avg       0.38      0.34      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 28, Train Loss: 1.649132951711997, Val Loss: 1.725075191921658\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.26      0.26      1423\n         joy       0.36      0.47      0.41      2047\n        fear       0.10      0.12      0.11       336\n     disgust       0.10      0.13      0.11       372\n     neutral       0.57      0.39      0.46      5299\n    surprise       0.30      0.38      0.34      1656\n     sadness       0.23      0.33      0.27      1011\n\n    accuracy                           0.37     12144\n   macro avg       0.27      0.30      0.28     12144\nweighted avg       0.40      0.37      0.37     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.24      0.24       192\n         joy       0.40      0.55      0.47       254\n        fear       0.05      0.08      0.06        37\n     disgust       0.04      0.07      0.05        42\n     neutral       0.51      0.32      0.39       630\n    surprise       0.31      0.39      0.34       184\n     sadness       0.25      0.31      0.27       136\n\n    accuracy                           0.34      1475\n   macro avg       0.26      0.28      0.26      1475\nweighted avg       0.38      0.34      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 29, Train Loss: 1.636827065394475, Val Loss: 1.7225959698359172\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.29      0.28      1423\n         joy       0.37      0.48      0.42      2047\n        fear       0.11      0.20      0.15       336\n     disgust       0.13      0.18      0.15       372\n     neutral       0.58      0.38      0.46      5299\n    surprise       0.31      0.39      0.34      1656\n     sadness       0.26      0.33      0.29      1011\n\n    accuracy                           0.37     12144\n   macro avg       0.29      0.32      0.30     12144\nweighted avg       0.42      0.37      0.38     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.26      0.25       192\n         joy       0.40      0.54      0.46       254\n        fear       0.05      0.08      0.07        37\n     disgust       0.04      0.07      0.05        42\n     neutral       0.52      0.31      0.39       630\n    surprise       0.30      0.39      0.34       184\n     sadness       0.25      0.32      0.28       136\n\n    accuracy                           0.34      1475\n   macro avg       0.26      0.28      0.26      1475\nweighted avg       0.39      0.34      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 30, Train Loss: 1.62536509678914, Val Loss: 1.7210274404949613\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.26      0.26      1423\n         joy       0.37      0.47      0.41      2047\n        fear       0.13      0.15      0.14       336\n     disgust       0.12      0.20      0.15       372\n     neutral       0.58      0.41      0.48      5299\n    surprise       0.32      0.39      0.35      1656\n     sadness       0.26      0.35      0.30      1011\n\n    accuracy                           0.38     12144\n   macro avg       0.29      0.32      0.30     12144\nweighted avg       0.42      0.38      0.39     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.27      0.26       192\n         joy       0.40      0.55      0.46       254\n        fear       0.06      0.08      0.07        37\n     disgust       0.05      0.10      0.06        42\n     neutral       0.52      0.31      0.39       630\n    surprise       0.31      0.40      0.35       184\n     sadness       0.25      0.31      0.28       136\n\n    accuracy                           0.34      1475\n   macro avg       0.26      0.29      0.27      1475\nweighted avg       0.39      0.34      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 31, Train Loss: 1.612255668028807, Val Loss: 1.7189617554346721\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.31      0.29      1423\n         joy       0.38      0.49      0.42      2047\n        fear       0.14      0.21      0.16       336\n     disgust       0.13      0.22      0.17       372\n     neutral       0.58      0.38      0.46      5299\n    surprise       0.33      0.41      0.36      1656\n     sadness       0.26      0.33      0.29      1011\n\n    accuracy                           0.38     12144\n   macro avg       0.30      0.33      0.31     12144\nweighted avg       0.42      0.38      0.39     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.26      0.25       192\n         joy       0.40      0.56      0.46       254\n        fear       0.06      0.08      0.07        37\n     disgust       0.05      0.10      0.07        42\n     neutral       0.52      0.32      0.39       630\n    surprise       0.31      0.40      0.35       184\n     sadness       0.25      0.31      0.28       136\n\n    accuracy                           0.35      1475\n   macro avg       0.26      0.29      0.27      1475\nweighted avg       0.39      0.35      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 32, Train Loss: 1.6136490901311238, Val Loss: 1.7175477743148804\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.29      0.29      1423\n         joy       0.37      0.47      0.41      2047\n        fear       0.14      0.20      0.16       336\n     disgust       0.12      0.19      0.15       372\n     neutral       0.58      0.38      0.46      5299\n    surprise       0.32      0.42      0.37      1656\n     sadness       0.25      0.35      0.29      1011\n\n    accuracy                           0.38     12144\n   macro avg       0.30      0.33      0.30     12144\nweighted avg       0.42      0.38      0.39     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.24      0.24       192\n         joy       0.40      0.55      0.46       254\n        fear       0.06      0.08      0.07        37\n     disgust       0.05      0.10      0.06        42\n     neutral       0.52      0.32      0.40       630\n    surprise       0.31      0.40      0.35       184\n     sadness       0.25      0.31      0.28       136\n\n    accuracy                           0.35      1475\n   macro avg       0.26      0.29      0.27      1475\nweighted avg       0.39      0.35      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.11it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 33, Train Loss: 1.598072146758055, Val Loss: 1.715517282485962\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.29      0.29      0.29      1423\n         joy       0.38      0.50      0.43      2047\n        fear       0.12      0.20      0.15       336\n     disgust       0.13      0.17      0.15       372\n     neutral       0.60      0.40      0.48      5299\n    surprise       0.34      0.42      0.37      1656\n     sadness       0.26      0.35      0.30      1011\n\n    accuracy                           0.39     12144\n   macro avg       0.30      0.33      0.31     12144\nweighted avg       0.43      0.39      0.40     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.23      0.24       192\n         joy       0.40      0.54      0.46       254\n        fear       0.06      0.08      0.07        37\n     disgust       0.05      0.12      0.07        42\n     neutral       0.53      0.32      0.40       630\n    surprise       0.30      0.42      0.35       184\n     sadness       0.25      0.31      0.27       136\n\n    accuracy                           0.35      1475\n   macro avg       0.26      0.29      0.27      1475\nweighted avg       0.39      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.12it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 34, Train Loss: 1.5881129992313874, Val Loss: 1.7127839856677585\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.30      0.29      1423\n         joy       0.38      0.49      0.43      2047\n        fear       0.13      0.18      0.15       336\n     disgust       0.14      0.23      0.17       372\n     neutral       0.59      0.40      0.48      5299\n    surprise       0.34      0.41      0.37      1656\n     sadness       0.26      0.36      0.30      1011\n\n    accuracy                           0.39     12144\n   macro avg       0.30      0.34      0.31     12144\nweighted avg       0.43      0.39      0.40     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.23      0.23       192\n         joy       0.41      0.53      0.46       254\n        fear       0.07      0.11      0.08        37\n     disgust       0.06      0.14      0.09        42\n     neutral       0.55      0.32      0.41       630\n    surprise       0.31      0.40      0.35       184\n     sadness       0.23      0.32      0.27       136\n\n    accuracy                           0.35      1475\n   macro avg       0.27      0.29      0.27      1475\nweighted avg       0.40      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.09it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 35, Train Loss: 1.5956791119697766, Val Loss: 1.712115102344089\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.30      0.30      0.30      1423\n         joy       0.38      0.49      0.43      2047\n        fear       0.12      0.20      0.15       336\n     disgust       0.14      0.22      0.17       372\n     neutral       0.59      0.40      0.48      5299\n    surprise       0.33      0.40      0.36      1656\n     sadness       0.27      0.37      0.31      1011\n\n    accuracy                           0.39     12144\n   macro avg       0.31      0.34      0.31     12144\nweighted avg       0.43      0.39      0.40     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.24      0.25       192\n         joy       0.39      0.56      0.46       254\n        fear       0.08      0.11      0.09        37\n     disgust       0.06      0.14      0.09        42\n     neutral       0.54      0.31      0.40       630\n    surprise       0.31      0.40      0.35       184\n     sadness       0.24      0.31      0.27       136\n\n    accuracy                           0.35      1475\n   macro avg       0.27      0.30      0.27      1475\nweighted avg       0.39      0.35      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 36, Train Loss: 1.5877994344784663, Val Loss: 1.7116719086964924\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.30      0.29      1423\n         joy       0.39      0.50      0.44      2047\n        fear       0.15      0.21      0.17       336\n     disgust       0.13      0.23      0.17       372\n     neutral       0.60      0.40      0.48      5299\n    surprise       0.35      0.41      0.37      1656\n     sadness       0.28      0.37      0.32      1011\n\n    accuracy                           0.39     12144\n   macro avg       0.31      0.35      0.32     12144\nweighted avg       0.44      0.39      0.41     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.23      0.24       192\n         joy       0.40      0.55      0.46       254\n        fear       0.08      0.11      0.09        37\n     disgust       0.06      0.14      0.08        42\n     neutral       0.56      0.31      0.40       630\n    surprise       0.30      0.43      0.35       184\n     sadness       0.25      0.31      0.27       136\n\n    accuracy                           0.35      1475\n   macro avg       0.27      0.30      0.27      1475\nweighted avg       0.40      0.35      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.08it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 37, Train Loss: 1.5713615341064258, Val Loss: 1.7109815279642742\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.28      0.27      1423\n         joy       0.39      0.49      0.44      2047\n        fear       0.13      0.21      0.16       336\n     disgust       0.13      0.22      0.16       372\n     neutral       0.60      0.40      0.48      5299\n    surprise       0.33      0.43      0.37      1656\n     sadness       0.27      0.36      0.31      1011\n\n    accuracy                           0.39     12144\n   macro avg       0.30      0.34      0.31     12144\nweighted avg       0.44      0.39      0.40     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.21      0.18      0.19       192\n         joy       0.38      0.57      0.45       254\n        fear       0.07      0.11      0.09        37\n     disgust       0.06      0.17      0.09        42\n     neutral       0.55      0.30      0.39       630\n    surprise       0.32      0.40      0.36       184\n     sadness       0.24      0.33      0.28       136\n\n    accuracy                           0.34      1475\n   macro avg       0.26      0.29      0.26      1475\nweighted avg       0.39      0.34      0.34      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.08it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 38, Train Loss: 1.5753706571383355, Val Loss: 1.7090126276016235\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.29      0.27      0.28      1423\n         joy       0.39      0.50      0.44      2047\n        fear       0.14      0.24      0.18       336\n     disgust       0.14      0.25      0.18       372\n     neutral       0.59      0.39      0.47      5299\n    surprise       0.33      0.41      0.37      1656\n     sadness       0.28      0.38      0.32      1011\n\n    accuracy                           0.39     12144\n   macro avg       0.31      0.35      0.32     12144\nweighted avg       0.44      0.39      0.40     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.26      0.26       192\n         joy       0.39      0.56      0.46       254\n        fear       0.09      0.14      0.11        37\n     disgust       0.06      0.17      0.09        42\n     neutral       0.56      0.30      0.39       630\n    surprise       0.30      0.41      0.35       184\n     sadness       0.26      0.29      0.27       136\n\n    accuracy                           0.35      1475\n   macro avg       0.27      0.30      0.28      1475\nweighted avg       0.40      0.35      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.09it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 39, Train Loss: 1.5687334904303918, Val Loss: 1.706773082415263\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.29      0.31      0.30      1423\n         joy       0.39      0.49      0.43      2047\n        fear       0.13      0.22      0.17       336\n     disgust       0.14      0.28      0.19       372\n     neutral       0.60      0.38      0.46      5299\n    surprise       0.33      0.42      0.37      1656\n     sadness       0.27      0.36      0.31      1011\n\n    accuracy                           0.38     12144\n   macro avg       0.31      0.35      0.32     12144\nweighted avg       0.44      0.38      0.40     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.23      0.22      0.23       192\n         joy       0.39      0.55      0.46       254\n        fear       0.08      0.14      0.10        37\n     disgust       0.06      0.14      0.08        42\n     neutral       0.55      0.32      0.41       630\n    surprise       0.32      0.41      0.36       184\n     sadness       0.27      0.34      0.30       136\n\n    accuracy                           0.35      1475\n   macro avg       0.27      0.30      0.28      1475\nweighted avg       0.40      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.11it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 40, Train Loss: 1.5661468597558827, Val Loss: 1.7081213262346056\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.30      0.28      0.29      1423\n         joy       0.38      0.51      0.44      2047\n        fear       0.14      0.21      0.16       336\n     disgust       0.16      0.24      0.19       372\n     neutral       0.60      0.41      0.49      5299\n    surprise       0.35      0.41      0.38      1656\n     sadness       0.27      0.37      0.31      1011\n\n    accuracy                           0.40     12144\n   macro avg       0.31      0.35      0.32     12144\nweighted avg       0.44      0.40      0.41     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.26      0.26       192\n         joy       0.41      0.55      0.47       254\n        fear       0.08      0.14      0.10        37\n     disgust       0.07      0.19      0.11        42\n     neutral       0.58      0.30      0.39       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.26      0.34      0.29       136\n\n    accuracy                           0.35      1475\n   macro avg       0.28      0.31      0.28      1475\nweighted avg       0.42      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.08it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 41, Train Loss: 1.557387005060147, Val Loss: 1.7080432971318562\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.29      0.30      0.29      1423\n         joy       0.39      0.50      0.44      2047\n        fear       0.14      0.23      0.17       336\n     disgust       0.14      0.26      0.19       372\n     neutral       0.61      0.38      0.47      5299\n    surprise       0.34      0.43      0.38      1656\n     sadness       0.27      0.36      0.31      1011\n\n    accuracy                           0.39     12144\n   macro avg       0.31      0.35      0.32     12144\nweighted avg       0.44      0.39      0.40     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.22      0.20      0.21       192\n         joy       0.40      0.55      0.47       254\n        fear       0.08      0.14      0.10        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.55      0.30      0.39       630\n    surprise       0.31      0.41      0.36       184\n     sadness       0.26      0.33      0.29       136\n\n    accuracy                           0.34      1475\n   macro avg       0.27      0.31      0.27      1475\nweighted avg       0.40      0.34      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.11it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 42, Train Loss: 1.545487798177279, Val Loss: 1.7072484228346083\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.31      0.30      0.31      1423\n         joy       0.39      0.50      0.44      2047\n        fear       0.13      0.22      0.16       336\n     disgust       0.14      0.26      0.19       372\n     neutral       0.60      0.40      0.48      5299\n    surprise       0.34      0.42      0.38      1656\n     sadness       0.28      0.38      0.32      1011\n\n    accuracy                           0.40     12144\n   macro avg       0.31      0.35      0.32     12144\nweighted avg       0.44      0.40      0.41     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.24      0.21      0.22       192\n         joy       0.40      0.56      0.47       254\n        fear       0.08      0.14      0.10        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.57      0.30      0.39       630\n    surprise       0.31      0.42      0.36       184\n     sadness       0.26      0.35      0.30       136\n\n    accuracy                           0.35      1475\n   macro avg       0.28      0.31      0.28      1475\nweighted avg       0.41      0.35      0.35      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.07it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 43, Train Loss: 1.5333443910647662, Val Loss: 1.7060230837927923\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.31      0.33      0.32      1423\n         joy       0.38      0.51      0.44      2047\n        fear       0.14      0.24      0.18       336\n     disgust       0.16      0.30      0.21       372\n     neutral       0.61      0.38      0.47      5299\n    surprise       0.35      0.42      0.39      1656\n     sadness       0.27      0.37      0.32      1011\n\n    accuracy                           0.40     12144\n   macro avg       0.32      0.36      0.33     12144\nweighted avg       0.45      0.40      0.41     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.23      0.24       192\n         joy       0.41      0.54      0.46       254\n        fear       0.10      0.16      0.12        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.54      0.34      0.42       630\n    surprise       0.33      0.41      0.37       184\n     sadness       0.27      0.32      0.29       136\n\n    accuracy                           0.36      1475\n   macro avg       0.28      0.31      0.29      1475\nweighted avg       0.41      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.10it/s]\n100%|██████████| 9/9 [00:00<00:00, 11.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 44, Train Loss: 1.5389107633859684, Val Loss: 1.7081514994303386\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.31      0.33      0.32      1423\n         joy       0.40      0.49      0.44      2047\n        fear       0.14      0.23      0.17       336\n     disgust       0.15      0.26      0.19       372\n     neutral       0.61      0.41      0.49      5299\n    surprise       0.36      0.43      0.39      1656\n     sadness       0.29      0.39      0.33      1011\n\n    accuracy                           0.41     12144\n   macro avg       0.32      0.36      0.33     12144\nweighted avg       0.45      0.41      0.42     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.23      0.19      0.21       192\n         joy       0.39      0.57      0.47       254\n        fear       0.09      0.14      0.11        37\n     disgust       0.06      0.19      0.10        42\n     neutral       0.56      0.31      0.40       630\n    surprise       0.32      0.43      0.37       184\n     sadness       0.26      0.34      0.29       136\n\n    accuracy                           0.35      1475\n   macro avg       0.28      0.31      0.28      1475\nweighted avg       0.40      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.09it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 45, Train Loss: 1.5358984974714427, Val Loss: 1.704556981722514\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.30      0.29      0.30      1423\n         joy       0.39      0.51      0.44      2047\n        fear       0.15      0.24      0.18       336\n     disgust       0.15      0.28      0.19       372\n     neutral       0.61      0.40      0.48      5299\n    surprise       0.36      0.45      0.40      1656\n     sadness       0.29      0.38      0.33      1011\n\n    accuracy                           0.40     12144\n   macro avg       0.32      0.36      0.33     12144\nweighted avg       0.45      0.40      0.41     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.26      0.26       192\n         joy       0.40      0.56      0.47       254\n        fear       0.10      0.16      0.12        37\n     disgust       0.07      0.17      0.10        42\n     neutral       0.57      0.31      0.40       630\n    surprise       0.31      0.42      0.36       184\n     sadness       0.27      0.35      0.31       136\n\n    accuracy                           0.35      1475\n   macro avg       0.28      0.32      0.29      1475\nweighted avg       0.41      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.07it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 46, Train Loss: 1.527077003931388, Val Loss: 1.706733054584927\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.30      0.30      0.30      1423\n         joy       0.40      0.51      0.45      2047\n        fear       0.13      0.27      0.18       336\n     disgust       0.17      0.27      0.21       372\n     neutral       0.62      0.38      0.47      5299\n    surprise       0.35      0.44      0.39      1656\n     sadness       0.28      0.40      0.33      1011\n\n    accuracy                           0.40     12144\n   macro avg       0.32      0.37      0.33     12144\nweighted avg       0.45      0.40      0.41     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.26      0.26       192\n         joy       0.40      0.56      0.47       254\n        fear       0.12      0.16      0.14        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.57      0.31      0.40       630\n    surprise       0.32      0.42      0.36       184\n     sadness       0.27      0.33      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.32      0.29      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.08it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 47, Train Loss: 1.5174539639399602, Val Loss: 1.706603791978624\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.29      0.33      0.31      1423\n         joy       0.41      0.51      0.45      2047\n        fear       0.15      0.28      0.20       336\n     disgust       0.16      0.31      0.21       372\n     neutral       0.62      0.40      0.48      5299\n    surprise       0.36      0.43      0.39      1656\n     sadness       0.31      0.38      0.34      1011\n\n    accuracy                           0.41     12144\n   macro avg       0.33      0.38      0.34     12144\nweighted avg       0.46      0.41      0.42     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.24      0.25       192\n         joy       0.39      0.56      0.46       254\n        fear       0.11      0.16      0.13        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.56      0.33      0.41       630\n    surprise       0.32      0.42      0.37       184\n     sadness       0.27      0.32      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.32      0.29      1475\nweighted avg       0.41      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.09it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 48, Train Loss: 1.5136510561674068, Val Loss: 1.7081752353244357\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.29      0.29      0.29      1423\n         joy       0.39      0.50      0.44      2047\n        fear       0.14      0.24      0.17       336\n     disgust       0.18      0.31      0.23       372\n     neutral       0.62      0.40      0.49      5299\n    surprise       0.36      0.44      0.40      1656\n     sadness       0.30      0.40      0.34      1011\n\n    accuracy                           0.40     12144\n   macro avg       0.32      0.37      0.34     12144\nweighted avg       0.45      0.40      0.42     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.23      0.25       192\n         joy       0.41      0.54      0.46       254\n        fear       0.10      0.16      0.13        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.56      0.31      0.40       630\n    surprise       0.30      0.44      0.36       184\n     sadness       0.27      0.33      0.30       136\n\n    accuracy                           0.35      1475\n   macro avg       0.28      0.32      0.28      1475\nweighted avg       0.41      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 49, Train Loss: 1.521452423853752, Val Loss: 1.7073397503958807\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.31      0.32      0.31      1423\n         joy       0.39      0.52      0.45      2047\n        fear       0.15      0.28      0.20       336\n     disgust       0.15      0.30      0.20       372\n     neutral       0.63      0.39      0.48      5299\n    surprise       0.36      0.43      0.39      1656\n     sadness       0.29      0.38      0.33      1011\n\n    accuracy                           0.40     12144\n   macro avg       0.32      0.37      0.34     12144\nweighted avg       0.46      0.40      0.41     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.21      0.23       192\n         joy       0.41      0.55      0.47       254\n        fear       0.10      0.16      0.12        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.55      0.32      0.41       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.27      0.35      0.31       136\n\n    accuracy                           0.35      1475\n   macro avg       0.28      0.32      0.29      1475\nweighted avg       0.41      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 50, Train Loss: 1.5144555156047528, Val Loss: 1.7069223986731634\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.30      0.30      0.30      1423\n         joy       0.41      0.52      0.46      2047\n        fear       0.16      0.29      0.21       336\n     disgust       0.16      0.32      0.22       372\n     neutral       0.62      0.39      0.48      5299\n    surprise       0.35      0.44      0.39      1656\n     sadness       0.30      0.40      0.34      1011\n\n    accuracy                           0.40     12144\n   macro avg       0.33      0.38      0.34     12144\nweighted avg       0.46      0.40      0.42     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.26      0.26       192\n         joy       0.40      0.55      0.47       254\n        fear       0.11      0.16      0.13        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.56      0.31      0.40       630\n    surprise       0.30      0.42      0.35       184\n     sadness       0.28      0.35      0.31       136\n\n    accuracy                           0.35      1475\n   macro avg       0.28      0.32      0.29      1475\nweighted avg       0.41      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 51, Train Loss: 1.4963402992639787, Val Loss: 1.7062966691123114\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.31      0.32      0.32      1423\n         joy       0.41      0.51      0.45      2047\n        fear       0.17      0.29      0.22       336\n     disgust       0.15      0.31      0.20       372\n     neutral       0.62      0.41      0.49      5299\n    surprise       0.37      0.45      0.41      1656\n     sadness       0.30      0.41      0.35      1011\n\n    accuracy                           0.41     12144\n   macro avg       0.33      0.38      0.35     12144\nweighted avg       0.46      0.41      0.42     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.27      0.27       192\n         joy       0.41      0.56      0.47       254\n        fear       0.09      0.16      0.12        37\n     disgust       0.07      0.17      0.10        42\n     neutral       0.56      0.30      0.39       630\n    surprise       0.30      0.43      0.35       184\n     sadness       0.29      0.35      0.32       136\n\n    accuracy                           0.35      1475\n   macro avg       0.28      0.32      0.29      1475\nweighted avg       0.41      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.12it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 52, Train Loss: 1.4961135570819561, Val Loss: 1.7067065636316936\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.31      0.31      0.31      1423\n         joy       0.39      0.50      0.44      2047\n        fear       0.16      0.31      0.21       336\n     disgust       0.15      0.29      0.20       372\n     neutral       0.62      0.40      0.49      5299\n    surprise       0.36      0.43      0.39      1656\n     sadness       0.30      0.38      0.34      1011\n\n    accuracy                           0.40     12144\n   macro avg       0.33      0.38      0.34     12144\nweighted avg       0.46      0.40      0.42     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.26      0.26       192\n         joy       0.41      0.53      0.46       254\n        fear       0.10      0.19      0.13        37\n     disgust       0.08      0.21      0.12        42\n     neutral       0.57      0.30      0.39       630\n    surprise       0.30      0.45      0.36       184\n     sadness       0.27      0.33      0.30       136\n\n    accuracy                           0.35      1475\n   macro avg       0.28      0.32      0.29      1475\nweighted avg       0.41      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 53, Train Loss: 1.4985602161823175, Val Loss: 1.7073134846157498\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.31      0.33      0.32      1423\n         joy       0.41      0.52      0.46      2047\n        fear       0.14      0.30      0.19       336\n     disgust       0.15      0.30      0.20       372\n     neutral       0.62      0.39      0.48      5299\n    surprise       0.38      0.46      0.41      1656\n     sadness       0.33      0.43      0.37      1011\n\n    accuracy                           0.41     12144\n   macro avg       0.33      0.39      0.35     12144\nweighted avg       0.46      0.41      0.42     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.24      0.25       192\n         joy       0.40      0.56      0.47       254\n        fear       0.12      0.19      0.15        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.56      0.30      0.39       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.28      0.35      0.31       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.32      0.29      1475\nweighted avg       0.41      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 54, Train Loss: 1.4863532139704778, Val Loss: 1.706971287727356\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.32      0.33      0.32      1423\n         joy       0.41      0.52      0.46      2047\n        fear       0.17      0.31      0.22       336\n     disgust       0.17      0.34      0.23       372\n     neutral       0.63      0.40      0.49      5299\n    surprise       0.37      0.45      0.41      1656\n     sadness       0.32      0.43      0.37      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.34      0.40      0.36     12144\nweighted avg       0.47      0.42      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.24      0.26       192\n         joy       0.41      0.56      0.47       254\n        fear       0.12      0.22      0.16        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.57      0.31      0.40       630\n    surprise       0.31      0.44      0.36       184\n     sadness       0.29      0.35      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 55, Train Loss: 1.478952713501759, Val Loss: 1.7066558731926813\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.33      0.34      0.33      1423\n         joy       0.40      0.51      0.45      2047\n        fear       0.16      0.30      0.21       336\n     disgust       0.16      0.32      0.21       372\n     neutral       0.62      0.40      0.49      5299\n    surprise       0.37      0.46      0.41      1656\n     sadness       0.32      0.40      0.35      1011\n\n    accuracy                           0.41     12144\n   macro avg       0.34      0.39      0.35     12144\nweighted avg       0.46      0.41      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.24      0.26       192\n         joy       0.41      0.56      0.47       254\n        fear       0.12      0.19      0.14        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.56      0.31      0.40       630\n    surprise       0.31      0.42      0.36       184\n     sadness       0.28      0.36      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.41      0.36      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.10it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 56, Train Loss: 1.4837009066190474, Val Loss: 1.7061360014809503\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.34      0.34      1423\n         joy       0.42      0.52      0.46      2047\n        fear       0.14      0.27      0.19       336\n     disgust       0.16      0.34      0.22       372\n     neutral       0.63      0.39      0.48      5299\n    surprise       0.37      0.45      0.41      1656\n     sadness       0.30      0.43      0.35      1011\n\n    accuracy                           0.41     12144\n   macro avg       0.34      0.39      0.35     12144\nweighted avg       0.47      0.41      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.24      0.25       192\n         joy       0.41      0.54      0.46       254\n        fear       0.12      0.22      0.16        37\n     disgust       0.06      0.19      0.10        42\n     neutral       0.57      0.32      0.41       630\n    surprise       0.31      0.42      0.36       184\n     sadness       0.28      0.34      0.30       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.32      0.29      1475\nweighted avg       0.41      0.35      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 57, Train Loss: 1.469772335810539, Val Loss: 1.7104040251837835\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.32      0.32      0.32      1423\n         joy       0.42      0.52      0.46      2047\n        fear       0.15      0.34      0.21       336\n     disgust       0.19      0.35      0.25       372\n     neutral       0.63      0.41      0.50      5299\n    surprise       0.37      0.43      0.40      1656\n     sadness       0.32      0.44      0.37      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.34      0.40      0.36     12144\nweighted avg       0.47      0.42      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.27      0.27       192\n         joy       0.41      0.56      0.47       254\n        fear       0.14      0.22      0.17        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.56      0.30      0.39       630\n    surprise       0.31      0.45      0.37       184\n     sadness       0.29      0.33      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 58, Train Loss: 1.457829400514945, Val Loss: 1.7074691189659967\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.32      0.35      0.33      1423\n         joy       0.42      0.54      0.47      2047\n        fear       0.18      0.31      0.23       336\n     disgust       0.17      0.38      0.23       372\n     neutral       0.63      0.39      0.48      5299\n    surprise       0.37      0.47      0.42      1656\n     sadness       0.33      0.40      0.36      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.35      0.41      0.36     12144\nweighted avg       0.47      0.42      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.23      0.25       192\n         joy       0.42      0.53      0.47       254\n        fear       0.12      0.22      0.16        37\n     disgust       0.06      0.19      0.10        42\n     neutral       0.57      0.34      0.42       630\n    surprise       0.32      0.43      0.37       184\n     sadness       0.28      0.38      0.32       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.38      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.17it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 59, Train Loss: 1.4564228990139105, Val Loss: 1.7110645373662312\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.33      0.30      0.31      1423\n         joy       0.42      0.50      0.46      2047\n        fear       0.17      0.36      0.23       336\n     disgust       0.16      0.33      0.22       372\n     neutral       0.63      0.43      0.51      5299\n    surprise       0.38      0.44      0.41      1656\n     sadness       0.30      0.41      0.35      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.34      0.40      0.35     12144\nweighted avg       0.47      0.42      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.40      0.57      0.47       254\n        fear       0.14      0.22      0.17        37\n     disgust       0.06      0.19      0.10        42\n     neutral       0.57      0.31      0.40       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.29      0.35      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.12it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 60, Train Loss: 1.4681115394983537, Val Loss: 1.7109691037072077\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.34      0.34      0.34      1423\n         joy       0.42      0.55      0.47      2047\n        fear       0.15      0.30      0.20       336\n     disgust       0.18      0.37      0.24       372\n     neutral       0.63      0.38      0.48      5299\n    surprise       0.37      0.45      0.41      1656\n     sadness       0.31      0.43      0.36      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.34      0.40      0.36     12144\nweighted avg       0.47      0.42      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.25      0.26       192\n         joy       0.41      0.55      0.47       254\n        fear       0.12      0.22      0.16        37\n     disgust       0.07      0.21      0.10        42\n     neutral       0.57      0.32      0.41       630\n    surprise       0.32      0.43      0.37       184\n     sadness       0.30      0.33      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.17it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 61, Train Loss: 1.4616115383612804, Val Loss: 1.7115237183041043\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.32      0.34      0.33      1423\n         joy       0.42      0.50      0.46      2047\n        fear       0.17      0.31      0.22       336\n     disgust       0.17      0.37      0.23       372\n     neutral       0.64      0.42      0.51      5299\n    surprise       0.38      0.45      0.41      1656\n     sadness       0.31      0.39      0.35      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.34      0.40      0.36     12144\nweighted avg       0.47      0.42      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.22      0.24       192\n         joy       0.41      0.58      0.48       254\n        fear       0.11      0.22      0.15        37\n     disgust       0.07      0.21      0.10        42\n     neutral       0.57      0.30      0.39       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.28      0.36      0.31       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 62, Train Loss: 1.4503311407871735, Val Loss: 1.7116856707466974\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.33      0.33      0.33      1423\n         joy       0.42      0.52      0.46      2047\n        fear       0.17      0.37      0.24       336\n     disgust       0.16      0.38      0.23       372\n     neutral       0.64      0.40      0.49      5299\n    surprise       0.38      0.46      0.42      1656\n     sadness       0.32      0.43      0.37      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.35      0.41      0.36     12144\nweighted avg       0.48      0.42      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.22      0.24       192\n         joy       0.41      0.57      0.47       254\n        fear       0.12      0.22      0.16        37\n     disgust       0.06      0.17      0.08        42\n     neutral       0.58      0.32      0.41       630\n    surprise       0.32      0.44      0.37       184\n     sadness       0.29      0.35      0.32       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 63, Train Loss: 1.44586332486226, Val Loss: 1.7125195927090116\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.33      0.33      0.33      1423\n         joy       0.42      0.53      0.47      2047\n        fear       0.18      0.35      0.23       336\n     disgust       0.17      0.38      0.24       372\n     neutral       0.63      0.41      0.50      5299\n    surprise       0.38      0.45      0.41      1656\n     sadness       0.31      0.41      0.35      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.35      0.41      0.36     12144\nweighted avg       0.47      0.42      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.40      0.57      0.47       254\n        fear       0.11      0.22      0.15        37\n     disgust       0.06      0.17      0.09        42\n     neutral       0.57      0.32      0.41       630\n    surprise       0.31      0.42      0.36       184\n     sadness       0.28      0.35      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 64, Train Loss: 1.4461358052033644, Val Loss: 1.7115183141496446\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.32      0.33      0.32      1423\n         joy       0.42      0.53      0.47      2047\n        fear       0.19      0.37      0.25       336\n     disgust       0.18      0.37      0.25       372\n     neutral       0.63      0.41      0.50      5299\n    surprise       0.39      0.45      0.42      1656\n     sadness       0.32      0.45      0.37      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.35      0.41      0.37     12144\nweighted avg       0.48      0.42      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.23      0.25       192\n         joy       0.41      0.56      0.47       254\n        fear       0.11      0.22      0.15        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.58      0.30      0.40       630\n    surprise       0.31      0.44      0.36       184\n     sadness       0.28      0.35      0.31       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 65, Train Loss: 1.4405741171959119, Val Loss: 1.7104186481899686\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.33      0.35      0.34      1423\n         joy       0.41      0.52      0.46      2047\n        fear       0.18      0.39      0.25       336\n     disgust       0.18      0.35      0.24       372\n     neutral       0.64      0.40      0.49      5299\n    surprise       0.38      0.47      0.42      1656\n     sadness       0.34      0.42      0.38      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.35      0.41      0.37     12144\nweighted avg       0.48      0.42      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.23      0.24       192\n         joy       0.41      0.54      0.46       254\n        fear       0.12      0.22      0.15        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.57      0.31      0.41       630\n    surprise       0.32      0.43      0.36       184\n     sadness       0.27      0.35      0.30       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 66, Train Loss: 1.443087012339861, Val Loss: 1.713050127029419\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.33      0.33      0.33      1423\n         joy       0.43      0.52      0.47      2047\n        fear       0.17      0.35      0.23       336\n     disgust       0.18      0.41      0.25       372\n     neutral       0.65      0.42      0.51      5299\n    surprise       0.39      0.45      0.42      1656\n     sadness       0.31      0.42      0.36      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.35      0.41      0.37     12144\nweighted avg       0.48      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.25      0.26       192\n         joy       0.40      0.58      0.47       254\n        fear       0.12      0.22      0.16        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.58      0.31      0.40       630\n    surprise       0.32      0.42      0.36       184\n     sadness       0.28      0.35      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 67, Train Loss: 1.4204427278958833, Val Loss: 1.7107525666554768\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.34      0.34      0.34      1423\n         joy       0.41      0.54      0.47      2047\n        fear       0.18      0.34      0.23       336\n     disgust       0.19      0.42      0.26       372\n     neutral       0.64      0.39      0.48      5299\n    surprise       0.38      0.47      0.42      1656\n     sadness       0.33      0.44      0.38      1011\n\n    accuracy                           0.42     12144\n   macro avg       0.35      0.42      0.37     12144\nweighted avg       0.48      0.42      0.43     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.25      0.23      0.24       192\n         joy       0.41      0.54      0.46       254\n        fear       0.12      0.22      0.15        37\n     disgust       0.08      0.24      0.11        42\n     neutral       0.56      0.32      0.40       630\n    surprise       0.33      0.42      0.37       184\n     sadness       0.27      0.35      0.30       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.41      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 68, Train Loss: 1.4225466908552709, Val Loss: 1.7134182453155518\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.33      0.33      0.33      1423\n         joy       0.43      0.50      0.46      2047\n        fear       0.17      0.36      0.23       336\n     disgust       0.18      0.41      0.25       372\n     neutral       0.65      0.41      0.50      5299\n    surprise       0.39      0.47      0.43      1656\n     sadness       0.33      0.45      0.38      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.35      0.42      0.37     12144\nweighted avg       0.48      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.40      0.54      0.46       254\n        fear       0.11      0.22      0.15        37\n     disgust       0.06      0.19      0.09        42\n     neutral       0.57      0.34      0.42       630\n    surprise       0.33      0.42      0.37       184\n     sadness       0.29      0.34      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.38      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.17it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 69, Train Loss: 1.4177716725911849, Val Loss: 1.7155628734164767\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.33      0.34      0.33      1423\n         joy       0.43      0.53      0.48      2047\n        fear       0.19      0.40      0.26       336\n     disgust       0.19      0.40      0.25       372\n     neutral       0.64      0.41      0.50      5299\n    surprise       0.39      0.47      0.42      1656\n     sadness       0.34      0.43      0.38      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.36      0.43      0.38     12144\nweighted avg       0.48      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.25      0.26       192\n         joy       0.40      0.57      0.47       254\n        fear       0.12      0.22      0.15        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.58      0.31      0.40       630\n    surprise       0.31      0.42      0.36       184\n     sadness       0.28      0.34      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 70, Train Loss: 1.4296374382116857, Val Loss: 1.7175837490293715\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.34      0.35      0.34      1423\n         joy       0.42      0.52      0.47      2047\n        fear       0.17      0.37      0.24       336\n     disgust       0.17      0.36      0.24       372\n     neutral       0.65      0.41      0.50      5299\n    surprise       0.39      0.44      0.41      1656\n     sadness       0.31      0.43      0.36      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.35      0.41      0.37     12144\nweighted avg       0.48      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.25      0.26       192\n         joy       0.40      0.56      0.47       254\n        fear       0.11      0.22      0.15        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.58      0.30      0.40       630\n    surprise       0.30      0.43      0.36       184\n     sadness       0.29      0.33      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 71, Train Loss: 1.423938430272616, Val Loss: 1.7159500519434612\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.34      0.34      0.34      1423\n         joy       0.42      0.54      0.47      2047\n        fear       0.17      0.36      0.23       336\n     disgust       0.18      0.39      0.25       372\n     neutral       0.65      0.40      0.50      5299\n    surprise       0.39      0.47      0.43      1656\n     sadness       0.32      0.43      0.36      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.35      0.42      0.37     12144\nweighted avg       0.48      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.25      0.26       192\n         joy       0.42      0.53      0.47       254\n        fear       0.11      0.22      0.15        37\n     disgust       0.06      0.19      0.10        42\n     neutral       0.56      0.32      0.41       630\n    surprise       0.32      0.45      0.37       184\n     sadness       0.28      0.34      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 72, Train Loss: 1.4198924700419109, Val Loss: 1.7171350982454088\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.34      0.35      1423\n         joy       0.43      0.54      0.48      2047\n        fear       0.18      0.38      0.24       336\n     disgust       0.19      0.41      0.26       372\n     neutral       0.64      0.41      0.50      5299\n    surprise       0.40      0.48      0.44      1656\n     sadness       0.32      0.42      0.37      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.36      0.43      0.38     12144\nweighted avg       0.49      0.44      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.25      0.26       192\n         joy       0.41      0.55      0.47       254\n        fear       0.12      0.24      0.16        37\n     disgust       0.07      0.24      0.11        42\n     neutral       0.57      0.30      0.39       630\n    surprise       0.31      0.42      0.36       184\n     sadness       0.28      0.34      0.31       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 73, Train Loss: 1.4099859213217711, Val Loss: 1.720586405860053\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.34      0.34      0.34      1423\n         joy       0.43      0.51      0.47      2047\n        fear       0.17      0.38      0.24       336\n     disgust       0.18      0.41      0.25       372\n     neutral       0.64      0.40      0.49      5299\n    surprise       0.39      0.48      0.43      1656\n     sadness       0.35      0.44      0.39      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.36      0.42      0.37     12144\nweighted avg       0.48      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.25      0.26       192\n         joy       0.39      0.57      0.46       254\n        fear       0.12      0.22      0.15        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.59      0.30      0.40       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.28      0.33      0.30       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 74, Train Loss: 1.4103559790513454, Val Loss: 1.7184532748328314\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.34      0.34      0.34      1423\n         joy       0.42      0.55      0.48      2047\n        fear       0.19      0.38      0.25       336\n     disgust       0.20      0.38      0.26       372\n     neutral       0.65      0.40      0.50      5299\n    surprise       0.40      0.49      0.44      1656\n     sadness       0.31      0.43      0.36      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.36      0.42      0.37     12144\nweighted avg       0.49      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.26      0.26       192\n         joy       0.42      0.52      0.46       254\n        fear       0.11      0.24      0.16        37\n     disgust       0.07      0.24      0.11        42\n     neutral       0.57      0.31      0.40       630\n    surprise       0.32      0.43      0.37       184\n     sadness       0.28      0.35      0.31       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.35      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 75, Train Loss: 1.3946388944601402, Val Loss: 1.7222965425915189\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.33      0.33      0.33      1423\n         joy       0.43      0.53      0.48      2047\n        fear       0.20      0.42      0.27       336\n     disgust       0.19      0.43      0.26       372\n     neutral       0.65      0.41      0.50      5299\n    surprise       0.39      0.47      0.43      1656\n     sadness       0.34      0.45      0.39      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.36      0.43      0.38     12144\nweighted avg       0.49      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.25      0.26       192\n         joy       0.40      0.56      0.47       254\n        fear       0.13      0.24      0.17        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.57      0.31      0.40       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.27      0.33      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 76, Train Loss: 1.3961760630974402, Val Loss: 1.720831619368659\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.36      0.34      0.35      1423\n         joy       0.42      0.55      0.48      2047\n        fear       0.16      0.37      0.23       336\n     disgust       0.21      0.44      0.28       372\n     neutral       0.65      0.40      0.49      5299\n    surprise       0.38      0.47      0.42      1656\n     sadness       0.34      0.45      0.39      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.36      0.43      0.38     12144\nweighted avg       0.49      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.26      0.26       192\n         joy       0.41      0.53      0.47       254\n        fear       0.13      0.24      0.17        37\n     disgust       0.07      0.21      0.10        42\n     neutral       0.57      0.32      0.41       630\n    surprise       0.31      0.42      0.36       184\n     sadness       0.29      0.35      0.32       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 77, Train Loss: 1.3904926486504383, Val Loss: 1.7209721406300862\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.36      0.36      1423\n         joy       0.43      0.51      0.46      2047\n        fear       0.17      0.35      0.23       336\n     disgust       0.19      0.41      0.26       372\n     neutral       0.65      0.42      0.51      5299\n    surprise       0.42      0.50      0.46      1656\n     sadness       0.34      0.43      0.38      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.36      0.43      0.38     12144\nweighted avg       0.49      0.44      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.27      0.27       192\n         joy       0.42      0.54      0.47       254\n        fear       0.13      0.22      0.16        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.58      0.31      0.41       630\n    surprise       0.31      0.45      0.36       184\n     sadness       0.27      0.35      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 78, Train Loss: 1.3947073374039087, Val Loss: 1.7211313380135431\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.36      0.35      1423\n         joy       0.43      0.53      0.47      2047\n        fear       0.22      0.43      0.29       336\n     disgust       0.19      0.40      0.26       372\n     neutral       0.65      0.41      0.50      5299\n    surprise       0.40      0.48      0.43      1656\n     sadness       0.34      0.45      0.39      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.37      0.44      0.39     12144\nweighted avg       0.49      0.44      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.24      0.26       192\n         joy       0.41      0.56      0.47       254\n        fear       0.14      0.24      0.17        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.58      0.31      0.40       630\n    surprise       0.31      0.42      0.36       184\n     sadness       0.27      0.35      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 79, Train Loss: 1.3866589497297237, Val Loss: 1.7254516151216295\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.34      0.37      0.35      1423\n         joy       0.44      0.53      0.48      2047\n        fear       0.19      0.39      0.26       336\n     disgust       0.18      0.40      0.25       372\n     neutral       0.66      0.41      0.51      5299\n    surprise       0.41      0.48      0.44      1656\n     sadness       0.33      0.44      0.38      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.36      0.43      0.38     12144\nweighted avg       0.49      0.44      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.23      0.26       192\n         joy       0.41      0.57      0.47       254\n        fear       0.12      0.24      0.16        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.59      0.31      0.40       630\n    surprise       0.30      0.44      0.36       184\n     sadness       0.27      0.32      0.29       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.12it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 80, Train Loss: 1.3883537298593767, Val Loss: 1.7218204074435763\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.34      0.34      0.34      1423\n         joy       0.42      0.56      0.48      2047\n        fear       0.19      0.39      0.25       336\n     disgust       0.20      0.43      0.27       372\n     neutral       0.66      0.38      0.49      5299\n    surprise       0.40      0.48      0.43      1656\n     sadness       0.33      0.46      0.38      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.36      0.44      0.38     12144\nweighted avg       0.49      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.26      0.27       192\n         joy       0.41      0.53      0.47       254\n        fear       0.11      0.24      0.15        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.57      0.33      0.42       630\n    surprise       0.32      0.42      0.37       184\n     sadness       0.29      0.34      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.38      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 81, Train Loss: 1.3864898895606017, Val Loss: 1.7245049873987834\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.36      0.36      1423\n         joy       0.43      0.53      0.47      2047\n        fear       0.20      0.42      0.27       336\n     disgust       0.18      0.42      0.25       372\n     neutral       0.66      0.41      0.50      5299\n    surprise       0.40      0.48      0.44      1656\n     sadness       0.34      0.45      0.39      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.37      0.44      0.38     12144\nweighted avg       0.50      0.44      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.29      0.26      0.27       192\n         joy       0.40      0.55      0.46       254\n        fear       0.12      0.24      0.16        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.57      0.32      0.41       630\n    surprise       0.32      0.43      0.37       184\n     sadness       0.29      0.32      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.12it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 82, Train Loss: 1.3718892702689538, Val Loss: 1.7233423391977947\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.35      0.35      1423\n         joy       0.43      0.55      0.48      2047\n        fear       0.20      0.44      0.28       336\n     disgust       0.21      0.43      0.28       372\n     neutral       0.64      0.40      0.50      5299\n    surprise       0.40      0.47      0.43      1656\n     sadness       0.33      0.44      0.38      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.37      0.44      0.38     12144\nweighted avg       0.49      0.43      0.44     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.26      0.27       192\n         joy       0.43      0.52      0.47       254\n        fear       0.12      0.24      0.16        37\n     disgust       0.06      0.17      0.09        42\n     neutral       0.58      0.32      0.41       630\n    surprise       0.31      0.46      0.37       184\n     sadness       0.27      0.34      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 83, Train Loss: 1.3826329081486433, Val Loss: 1.7237215174569025\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.35      0.35      1423\n         joy       0.44      0.52      0.48      2047\n        fear       0.18      0.38      0.24       336\n     disgust       0.20      0.49      0.29       372\n     neutral       0.66      0.40      0.50      5299\n    surprise       0.39      0.48      0.43      1656\n     sadness       0.34      0.45      0.39      1011\n\n    accuracy                           0.43     12144\n   macro avg       0.36      0.44      0.38     12144\nweighted avg       0.49      0.43      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.26      0.27       192\n         joy       0.41      0.54      0.46       254\n        fear       0.12      0.24      0.16        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.57      0.34      0.43       630\n    surprise       0.33      0.42      0.37       184\n     sadness       0.28      0.32      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.38      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.17it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 84, Train Loss: 1.3608092268308003, Val Loss: 1.7283391157786052\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.36      0.35      1423\n         joy       0.44      0.55      0.49      2047\n        fear       0.21      0.44      0.29       336\n     disgust       0.21      0.45      0.28       372\n     neutral       0.66      0.42      0.52      5299\n    surprise       0.41      0.48      0.44      1656\n     sadness       0.34      0.45      0.39      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.37      0.45      0.39     12144\nweighted avg       0.50      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.41      0.55      0.47       254\n        fear       0.15      0.24      0.18        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.57      0.32      0.41       630\n    surprise       0.32      0.45      0.38       184\n     sadness       0.28      0.35      0.31       136\n\n    accuracy                           0.36      1475\n   macro avg       0.30      0.34      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.12it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 85, Train Loss: 1.3657306386874273, Val Loss: 1.7289856274922688\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.34      0.34      1423\n         joy       0.44      0.54      0.48      2047\n        fear       0.21      0.43      0.28       336\n     disgust       0.22      0.47      0.30       372\n     neutral       0.66      0.41      0.51      5299\n    surprise       0.40      0.51      0.45      1656\n     sadness       0.34      0.46      0.39      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.37      0.45      0.39     12144\nweighted avg       0.50      0.44      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.25      0.27       192\n         joy       0.41      0.54      0.47       254\n        fear       0.12      0.24      0.16        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.57      0.33      0.42       630\n    surprise       0.33      0.44      0.38       184\n     sadness       0.29      0.32      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.30      0.33      0.30      1475\nweighted avg       0.42      0.36      0.38      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 86, Train Loss: 1.360673739359929, Val Loss: 1.7284153170055814\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.37      0.36      1423\n         joy       0.43      0.52      0.47      2047\n        fear       0.19      0.40      0.25       336\n     disgust       0.21      0.48      0.29       372\n     neutral       0.65      0.42      0.51      5299\n    surprise       0.42      0.48      0.45      1656\n     sadness       0.33      0.44      0.38      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.37      0.44      0.39     12144\nweighted avg       0.50      0.44      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.41      0.57      0.47       254\n        fear       0.12      0.24      0.16        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.58      0.32      0.42       630\n    surprise       0.33      0.43      0.37       184\n     sadness       0.27      0.32      0.29       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.43      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.12it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 87, Train Loss: 1.3559928444715648, Val Loss: 1.7289659182230632\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.37      0.37      0.37      1423\n         joy       0.43      0.54      0.48      2047\n        fear       0.20      0.39      0.26       336\n     disgust       0.21      0.48      0.29       372\n     neutral       0.66      0.41      0.51      5299\n    surprise       0.41      0.47      0.44      1656\n     sadness       0.34      0.47      0.39      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.37      0.45      0.39     12144\nweighted avg       0.50      0.44      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.26      0.27       192\n         joy       0.42      0.53      0.47       254\n        fear       0.10      0.24      0.15        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.57      0.34      0.43       630\n    surprise       0.32      0.44      0.37       184\n     sadness       0.29      0.32      0.31       136\n\n    accuracy                           0.37      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.43      0.37      0.38      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 88, Train Loss: 1.3562494837320769, Val Loss: 1.732415344980028\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.34      0.35      0.34      1423\n         joy       0.44      0.54      0.49      2047\n        fear       0.19      0.40      0.26       336\n     disgust       0.20      0.45      0.28       372\n     neutral       0.66      0.42      0.51      5299\n    surprise       0.41      0.48      0.44      1656\n     sadness       0.35      0.44      0.39      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.37      0.44      0.39     12144\nweighted avg       0.50      0.44      0.45     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.23      0.26       192\n         joy       0.41      0.57      0.48       254\n        fear       0.10      0.24      0.14        37\n     disgust       0.06      0.17      0.09        42\n     neutral       0.59      0.33      0.42       630\n    surprise       0.31      0.45      0.37       184\n     sadness       0.28      0.31      0.29       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.43      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.14it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 89, Train Loss: 1.360482163918324, Val Loss: 1.7322368489371405\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.37      0.36      0.36      1423\n         joy       0.44      0.54      0.48      2047\n        fear       0.19      0.41      0.26       336\n     disgust       0.23      0.47      0.30       372\n     neutral       0.65      0.42      0.51      5299\n    surprise       0.41      0.48      0.44      1656\n     sadness       0.33      0.46      0.39      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.37      0.45      0.39     12144\nweighted avg       0.50      0.44      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.41      0.57      0.48       254\n        fear       0.12      0.24      0.16        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.58      0.33      0.42       630\n    surprise       0.32      0.43      0.37       184\n     sadness       0.28      0.32      0.30       136\n\n    accuracy                           0.37      1475\n   macro avg       0.29      0.34      0.30      1475\nweighted avg       0.43      0.37      0.38      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.15it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 90, Train Loss: 1.345500186467782, Val Loss: 1.732785357369317\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.37      0.36      0.36      1423\n         joy       0.43      0.54      0.48      2047\n        fear       0.19      0.43      0.26       336\n     disgust       0.22      0.46      0.30       372\n     neutral       0.66      0.42      0.51      5299\n    surprise       0.43      0.49      0.46      1656\n     sadness       0.35      0.46      0.39      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.38      0.45      0.40     12144\nweighted avg       0.50      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.26      0.26       192\n         joy       0.41      0.56      0.48       254\n        fear       0.12      0.24      0.17        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.58      0.31      0.41       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.27      0.32      0.29       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.16it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 91, Train Loss: 1.3387458118108602, Val Loss: 1.7364570829603407\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.37      0.36      1423\n         joy       0.45      0.54      0.49      2047\n        fear       0.22      0.45      0.29       336\n     disgust       0.20      0.49      0.29       372\n     neutral       0.67      0.41      0.51      5299\n    surprise       0.41      0.48      0.44      1656\n     sadness       0.34      0.44      0.38      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.38      0.45      0.39     12144\nweighted avg       0.50      0.44      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.41      0.57      0.47       254\n        fear       0.13      0.24      0.17        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.58      0.31      0.41       630\n    surprise       0.32      0.45      0.37       184\n     sadness       0.28      0.32      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.09it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 92, Train Loss: 1.3430834932205005, Val Loss: 1.7352396647135417\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.35      0.38      0.36      1423\n         joy       0.44      0.55      0.49      2047\n        fear       0.19      0.41      0.26       336\n     disgust       0.21      0.45      0.28       372\n     neutral       0.67      0.41      0.51      5299\n    surprise       0.42      0.49      0.45      1656\n     sadness       0.35      0.45      0.39      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.38      0.45      0.39     12144\nweighted avg       0.50      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.41      0.55      0.47       254\n        fear       0.11      0.24      0.15        37\n     disgust       0.07      0.24      0.11        42\n     neutral       0.57      0.31      0.40       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.28      0.33      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.34      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.12it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 93, Train Loss: 1.327998194939051, Val Loss: 1.7390151686138577\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.36      0.38      0.37      1423\n         joy       0.44      0.54      0.49      2047\n        fear       0.21      0.49      0.30       336\n     disgust       0.20      0.47      0.28       372\n     neutral       0.67      0.41      0.51      5299\n    surprise       0.42      0.49      0.46      1656\n     sadness       0.36      0.47      0.41      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.38      0.46      0.40     12144\nweighted avg       0.51      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.41      0.56      0.47       254\n        fear       0.11      0.24      0.16        37\n     disgust       0.08      0.26      0.12        42\n     neutral       0.58      0.32      0.41       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.29      0.32      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.34      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.06it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 94, Train Loss: 1.3500961256332886, Val Loss: 1.7377684513727825\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.37      0.36      0.37      1423\n         joy       0.44      0.53      0.48      2047\n        fear       0.20      0.42      0.27       336\n     disgust       0.21      0.48      0.29       372\n     neutral       0.66      0.43      0.52      5299\n    surprise       0.40      0.47      0.43      1656\n     sadness       0.34      0.45      0.39      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.37      0.45      0.39     12144\nweighted avg       0.50      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.24      0.25       192\n         joy       0.41      0.56      0.47       254\n        fear       0.11      0.24      0.15        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.58      0.31      0.41       630\n    surprise       0.31      0.45      0.37       184\n     sadness       0.28      0.32      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.02it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 95, Train Loss: 1.3384361083690937, Val Loss: 1.737867620256212\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.36      0.37      0.36      1423\n         joy       0.44      0.53      0.48      2047\n        fear       0.21      0.47      0.29       336\n     disgust       0.21      0.47      0.29       372\n     neutral       0.66      0.41      0.50      5299\n    surprise       0.41      0.49      0.44      1656\n     sadness       0.36      0.47      0.41      1011\n\n    accuracy                           0.44     12144\n   macro avg       0.38      0.46      0.40     12144\nweighted avg       0.50      0.44      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.24      0.26       192\n         joy       0.41      0.56      0.48       254\n        fear       0.11      0.24      0.15        37\n     disgust       0.08      0.24      0.12        42\n     neutral       0.58      0.31      0.40       630\n    surprise       0.31      0.43      0.36       184\n     sadness       0.28      0.32      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.34      0.29      1475\nweighted avg       0.43      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 96, Train Loss: 1.3366179107091365, Val Loss: 1.735300792588128\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.38      0.38      0.38      1423\n         joy       0.43      0.54      0.48      2047\n        fear       0.22      0.46      0.30       336\n     disgust       0.20      0.48      0.28       372\n     neutral       0.66      0.41      0.51      5299\n    surprise       0.40      0.50      0.45      1656\n     sadness       0.36      0.46      0.40      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.38      0.46      0.40     12144\nweighted avg       0.50      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.26      0.24      0.25       192\n         joy       0.42      0.57      0.48       254\n        fear       0.10      0.24      0.14        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.57      0.31      0.40       630\n    surprise       0.32      0.42      0.36       184\n     sadness       0.27      0.32      0.29       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.42      0.35      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.10it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 97, Train Loss: 1.328953946248079, Val Loss: 1.7405520412656996\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.36      0.39      0.37      1423\n         joy       0.45      0.54      0.49      2047\n        fear       0.20      0.46      0.28       336\n     disgust       0.22      0.48      0.30       372\n     neutral       0.66      0.41      0.51      5299\n    surprise       0.42      0.49      0.45      1656\n     sadness       0.35      0.48      0.41      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.38      0.46      0.40     12144\nweighted avg       0.51      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.29      0.24      0.26       192\n         joy       0.40      0.57      0.47       254\n        fear       0.12      0.24      0.16        37\n     disgust       0.09      0.26      0.13        42\n     neutral       0.58      0.32      0.41       630\n    surprise       0.32      0.43      0.37       184\n     sadness       0.29      0.32      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.30      0.34      0.30      1475\nweighted avg       0.43      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.13it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 98, Train Loss: 1.3239129812289507, Val Loss: 1.740078369776408\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.38      0.37      0.38      1423\n         joy       0.44      0.54      0.49      2047\n        fear       0.20      0.47      0.28       336\n     disgust       0.21      0.48      0.29       372\n     neutral       0.67      0.42      0.52      5299\n    surprise       0.40      0.48      0.44      1656\n     sadness       0.36      0.46      0.40      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.38      0.46      0.40     12144\nweighted avg       0.51      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.28      0.26      0.26       192\n         joy       0.40      0.57      0.47       254\n        fear       0.11      0.24      0.15        37\n     disgust       0.08      0.26      0.12        42\n     neutral       0.57      0.30      0.39       630\n    surprise       0.32      0.41      0.36       184\n     sadness       0.28      0.31      0.29       136\n\n    accuracy                           0.35      1475\n   macro avg       0.29      0.34      0.29      1475\nweighted avg       0.42      0.35      0.36      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.07it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 99, Train Loss: 1.3258145130597627, Val Loss: 1.7387599415249295\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.38      0.38      0.38      1423\n         joy       0.43      0.55      0.48      2047\n        fear       0.20      0.42      0.27       336\n     disgust       0.19      0.46      0.27       372\n     neutral       0.67      0.41      0.51      5299\n    surprise       0.42      0.50      0.45      1656\n     sadness       0.36      0.45      0.40      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.38      0.45      0.40     12144\nweighted avg       0.51      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.25      0.26       192\n         joy       0.43      0.54      0.48       254\n        fear       0.10      0.24      0.14        37\n     disgust       0.07      0.19      0.10        42\n     neutral       0.58      0.33      0.42       630\n    surprise       0.32      0.44      0.37       184\n     sadness       0.27      0.32      0.29       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.29      1475\nweighted avg       0.43      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 78/78 [00:15<00:00,  5.07it/s]\n100%|██████████| 9/9 [00:00<00:00, 12.48it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 100, Train Loss: 1.3298427584843757, Val Loss: 1.7410512897703383\nTrain Report: \n              precision    recall  f1-score   support\n\n       anger       0.36      0.36      0.36      1423\n         joy       0.45      0.53      0.49      2047\n        fear       0.22      0.48      0.30       336\n     disgust       0.20      0.49      0.29       372\n     neutral       0.66      0.41      0.50      5299\n    surprise       0.42      0.50      0.46      1656\n     sadness       0.33      0.46      0.39      1011\n\n    accuracy                           0.45     12144\n   macro avg       0.38      0.46      0.40     12144\nweighted avg       0.50      0.45      0.46     12144\n\nVal Report: \n              precision    recall  f1-score   support\n\n       anger       0.27      0.26      0.26       192\n         joy       0.41      0.56      0.47       254\n        fear       0.11      0.24      0.15        37\n     disgust       0.07      0.21      0.11        42\n     neutral       0.57      0.32      0.41       630\n    surprise       0.32      0.42      0.36       184\n     sadness       0.28      0.31      0.30       136\n\n    accuracy                           0.36      1475\n   macro avg       0.29      0.33      0.30      1475\nweighted avg       0.42      0.36      0.37      1475\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T11:18:46.982478Z","iopub.execute_input":"2024-04-23T11:18:46.983095Z","iopub.status.idle":"2024-04-23T11:18:50.506159Z","shell.execute_reply.started":"2024-04-23T11:18:46.983066Z","shell.execute_reply":"2024-04-23T11:18:50.505308Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.169 MB uploaded\\r'), FloatProgress(value=0.008216676810712111, max=1…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Macro train_f1</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>Macro val_f1</td><td>▁▂▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████▇██████████████</td></tr><tr><td>Weighted train_f1</td><td>▁▂▃▃▄▄▅▅▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇██▇███████</td></tr><tr><td>Weighted val_f1</td><td>▁▃▄▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇▇██</td></tr><tr><td>train_accuracy</td><td>▁▂▃▃▄▄▅▅▅▅▆▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇█▇██████████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▅▅▆▅▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇█▇████▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Macro train_f1</td><td>0.39837</td></tr><tr><td>Macro val_f1</td><td>0.2951</td></tr><tr><td>Weighted train_f1</td><td>0.45659</td></tr><tr><td>Weighted val_f1</td><td>0.37032</td></tr><tr><td>train_accuracy</td><td>0.4459</td></tr><tr><td>train_loss</td><td>1.32984</td></tr><tr><td>val_accuracy</td><td>0.35932</td></tr><tr><td>val_loss</td><td>1.74105</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">GPT2_Conv_Level</strong> at: <a href='https://wandb.ai/shreyas21563/TECPEC/runs/8gzhm64z' target=\"_blank\">https://wandb.ai/shreyas21563/TECPEC/runs/8gzhm64z</a><br/> View project at: <a href='https://wandb.ai/shreyas21563/TECPEC' target=\"_blank\">https://wandb.ai/shreyas21563/TECPEC</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240423_105145-8gzhm64z/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model, \"/kaggle/working/GPT2_Conv_Level.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T11:19:00.987061Z","iopub.execute_input":"2024-04-23T11:19:00.987895Z","iopub.status.idle":"2024-04-23T11:19:01.769391Z","shell.execute_reply.started":"2024-04-23T11:19:00.987859Z","shell.execute_reply":"2024-04-23T11:19:01.768438Z"},"trusted":true},"execution_count":17,"outputs":[]}]}