{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:02.393775Z","iopub.status.busy":"2024-04-22T17:53:02.393406Z","iopub.status.idle":"2024-04-22T17:53:02.399967Z","shell.execute_reply":"2024-04-22T17:53:02.398754Z","shell.execute_reply.started":"2024-04-22T17:53:02.393748Z"},"trusted":true},"outputs":[],"source":["import json\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report\n","import wandb\n","from transformers import RobertaPreTrainedModel, RobertaModel, RobertaConfig\n","import pickle\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:04.217633Z","iopub.status.busy":"2024-04-22T17:53:04.216736Z","iopub.status.idle":"2024-04-22T17:53:04.229129Z","shell.execute_reply":"2024-04-22T17:53:04.228008Z","shell.execute_reply.started":"2024-04-22T17:53:04.217590Z"},"trusted":true},"outputs":[],"source":["# Source: https://github.com/LCS2-IIITD/Emotion-Flip-Reasoning/blob/main/Dataloaders/nlp_utils.py\n","import string\n","import nltk\n","import re\n","\n","numbers = {\n","    \"0\":\"zero\",\n","    \"1\":\"one\",\n","    \"2\":\"two\",\n","    \"3\":\"three\",\n","    \"4\":\"four\",\n","    \"5\":\"five\",\n","    \"6\":\"six\",\n","    \"7\":\"seven\",\n","    \"8\":\"eight\",\n","    \"9\":\"nine\"\n","}\n","\n","def remove_puntuations(txt):\n","    punct = set(string.punctuation)\n","    txt = \" \".join(txt.split(\".\"))\n","    txt = \" \".join(txt.split(\"!\"))\n","    txt = \" \".join(txt.split(\"?\"))\n","    txt = \" \".join(txt.split(\":\"))\n","    txt = \" \".join(txt.split(\";\"))\n","    \n","    txt = \"\".join(ch for ch in txt if ch not in punct)\n","    return txt\n","\n","def number_to_words(txt):\n","    for k in numbers.keys():\n","        txt = txt.replace(k,numbers[k]+\" \")\n","    return txt\n","\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r'_',' ',text)\n","    text = number_to_words(text)\n","    text = remove_puntuations(text)\n","    text = ''.join([i if ord(i) < 128 else '' for i in text])\n","    text = ' '.join(text.split())\n","    return text"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:07.416426Z","iopub.status.busy":"2024-04-22T17:53:07.415653Z","iopub.status.idle":"2024-04-22T17:53:07.516597Z","shell.execute_reply":"2024-04-22T17:53:07.515677Z","shell.execute_reply.started":"2024-04-22T17:53:07.416392Z"},"trusted":true},"outputs":[],"source":["train_data = json.load(open('/kaggle/input/Dataset/ERC_utterance_level/train_utterance_level.json'))\n","val_data = json.load(open('/kaggle/input/Dataset/ERC_utterance_level/val_utterance_level.json'))"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:08.947984Z","iopub.status.busy":"2024-04-22T17:53:08.947052Z","iopub.status.idle":"2024-04-22T17:53:08.954685Z","shell.execute_reply":"2024-04-22T17:53:08.953568Z","shell.execute_reply.started":"2024-04-22T17:53:08.947947Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:10.700235Z","iopub.status.busy":"2024-04-22T17:53:10.699835Z","iopub.status.idle":"2024-04-22T17:53:10.705586Z","shell.execute_reply":"2024-04-22T17:53:10.704495Z","shell.execute_reply.started":"2024-04-22T17:53:10.700201Z"},"trusted":true},"outputs":[],"source":["emotion2int = {\n","    'anger': 0,\n","    'joy': 1,\n","    'fear': 2,\n","    'disgust': 3,\n","    'neutral': 4,\n","    'surprise': 5,\n","    'sadness': 6\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["L = []\n","for conversation in train_data:\n","    for utterance in conversation['conversation']:\n","        L.append(emotion2int[utterance['emotion']])\n","class_weights=compute_class_weight(class_weight='balanced',classes=list(emotion2int.values()), y=np.array(L))"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:12.895410Z","iopub.status.busy":"2024-04-22T17:53:12.894995Z","iopub.status.idle":"2024-04-22T17:53:12.979045Z","shell.execute_reply":"2024-04-22T17:53:12.977887Z","shell.execute_reply.started":"2024-04-22T17:53:12.895377Z"},"trusted":true},"outputs":[],"source":["utterance2vec = pickle.load(open('/kaggle/input/Dataset/Embeddings/sentence_transformer_utterance2vec_786.pkl', 'rb'))"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:14.504486Z","iopub.status.busy":"2024-04-22T17:53:14.503671Z","iopub.status.idle":"2024-04-22T17:53:14.517551Z","shell.execute_reply":"2024-04-22T17:53:14.516403Z","shell.execute_reply.started":"2024-04-22T17:53:14.504454Z"},"trusted":true},"outputs":[],"source":["MAX_CONV_LEN = 35\n","# Defined index 7 for padding\n","class ERC_Dataset_Utt_Level(Dataset):\n","    def __init__(self, data, utterance2vec, device):\n","        self.data = data\n","        self.utterance2vec = utterance2vec\n","        self.device = device\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        text = self.data[f'id_{idx+1}']['text']\n","        emotion = self.data[f'id_{idx+1}']['emotion']\n","        context = self.data[f'id_{idx+1}']['context']\n","\n","        context_embeddings = [torch.tensor(self.utterance2vec[preprocess_text(utterance)]).to(self.device) for utterance in context]\n","        target_embedding = torch.tensor(self.utterance2vec[preprocess_text(text)]).to(self.device)\n","        # context_embeddings.append(target_embedding)\n","        context_embeddings_cat = [torch.cat((emb, target_embedding)) for emb in context_embeddings]\n","        \n","        if(len(context_embeddings_cat)<MAX_CONV_LEN):\n","            num_pads = MAX_CONV_LEN - len(context_embeddings_cat)\n","            attention_mask = [1]*len(context_embeddings_cat) + [0]*num_pads\n","            context_embeddings_cat = context_embeddings_cat + [torch.zeros(768).to(self.device)]*num_pads  \n","            context_embeddings = context_embeddings + [torch.zeros(384).to(self.device)]*num_pads\n","        else:\n","            context_embeddings_cat = context_embeddings_cat[len(context_embeddings_cat)-MAX_CONV_LEN:]\n","            context_embeddings = context_embeddings[len(context_embeddings)-MAX_CONV_LEN:]\n","            attention_mask = [1]*MAX_CONV_LEN\n","        # if(len(context_embeddings)<MAX_CONV_LEN):\n","        #     num_pads = MAX_CONV_LEN - len(context_embeddings)\n","        #     attention_mask = [1]*len(context_embeddings) + [0]*num_pads\n","        #     # context_embeddings_cat = context_embeddings_cat + [torch.zeros(768).to(self.device)]*num_pads  \n","        #     context_embeddings = context_embeddings + [torch.zeros(786).to(self.device)]*num_pads\n","        # else:\n","        #     # context_embeddings_cat = context_embeddings_cat[len(context_embeddings_cat)-MAX_CONV_LEN:]\n","        #     context_embeddings = context_embeddings[len(context_embeddings)-MAX_CONV_LEN:]\n","        #     attention_mask = [1]*MAX_CONV_LEN\n","\n","        context_embeddings_cat = torch.stack(context_embeddings_cat)\n","        context_embeddings = torch.stack(context_embeddings)\n","        attention_mask = torch.tensor(attention_mask)\n","\n","        return {\n","            'context_embeddings_cat': context_embeddings_cat,\n","            'context_embeddings': context_embeddings,\n","            'target_embedding': target_embedding,\n","            'attention_mask': attention_mask,   \n","            'emotion': emotion2int[emotion]\n","        }"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:17.401854Z","iopub.status.busy":"2024-04-22T17:53:17.401457Z","iopub.status.idle":"2024-04-22T17:53:17.412330Z","shell.execute_reply":"2024-04-22T17:53:17.411191Z","shell.execute_reply.started":"2024-04-22T17:53:17.401823Z"},"trusted":true},"outputs":[],"source":["class RobertaForSentenceClassificationGivenContext(RobertaPreTrainedModel):\n","    def __init__(self, config,weights):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.config = config\n","        self.weights = weights\n","        self.roberta = RobertaModel(config)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.classifier = nn.Linear(int(config.hidden_size*1.5), config.num_labels)\n","        self.post_init()\n","\n","    def forward(self, context_embeds, target_embeds, attention_mask, labels=None):\n","        output = self.roberta(inputs_embeds=context_embeds, attention_mask=attention_mask)\n","        print(output.shape)\n","        pooled_output = output.pooler_output\n","        pooled_output = self.dropout(pooled_output)\n","        pooled_output_cat = torch.cat((pooled_output, target_embeds), 1)\n","        logits = self.classifier(pooled_output_cat)\n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss(weight=self.weights)\n","            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        return {'loss': loss, 'logits': logits}\n","        "]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:20.245269Z","iopub.status.busy":"2024-04-22T17:53:20.244856Z","iopub.status.idle":"2024-04-22T17:53:20.262272Z","shell.execute_reply":"2024-04-22T17:53:20.261260Z","shell.execute_reply.started":"2024-04-22T17:53:20.245238Z"},"trusted":true},"outputs":[],"source":["train_dataset = ERC_Dataset_Utt_Level(train_data, utterance2vec, device)\n","val_dataset = ERC_Dataset_Utt_Level(val_data, utterance2vec, device)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:22.646239Z","iopub.status.busy":"2024-04-22T17:53:22.645821Z","iopub.status.idle":"2024-04-22T17:53:23.375001Z","shell.execute_reply":"2024-04-22T17:53:23.373905Z","shell.execute_reply.started":"2024-04-22T17:53:22.646203Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSentenceClassificationGivenContext were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["config = RobertaConfig.from_pretrained('roberta-base', num_labels=7)\n","model = RobertaForSentenceClassificationGivenContext.from_pretrained('roberta-base', config=config, weights=torch.from_numpy(class_weights).float()).to(device)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:25.723652Z","iopub.status.busy":"2024-04-22T17:53:25.723243Z","iopub.status.idle":"2024-04-22T17:53:25.731641Z","shell.execute_reply":"2024-04-22T17:53:25.730511Z","shell.execute_reply.started":"2024-04-22T17:53:25.723623Z"},"trusted":true},"outputs":[],"source":["epochs = 30\n","optimizer = AdamW(model.parameters(), lr=1e-6)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:27.909154Z","iopub.status.busy":"2024-04-22T17:53:27.908459Z","iopub.status.idle":"2024-04-22T17:53:28.145814Z","shell.execute_reply":"2024-04-22T17:53:28.144798Z","shell.execute_reply.started":"2024-04-22T17:53:27.909120Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"wandb_login_key\")\n","wandb.login(key=secret_value_0)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:30.652581Z","iopub.status.busy":"2024-04-22T17:53:30.652071Z","iopub.status.idle":"2024-04-22T17:53:47.361853Z","shell.execute_reply":"2024-04-22T17:53:47.360814Z","shell.execute_reply.started":"2024-04-22T17:53:30.652546Z"},"trusted":true},"outputs":[{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240422_175330-z4lekcdz</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/shreyas21563/TECPEC/runs/z4lekcdz' target=\"_blank\">RoBERTa_cat_Utt_Level</a></strong> to <a href='https://wandb.ai/shreyas21563/TECPEC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/shreyas21563/TECPEC' target=\"_blank\">https://wandb.ai/shreyas21563/TECPEC</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/shreyas21563/TECPEC/runs/z4lekcdz' target=\"_blank\">https://wandb.ai/shreyas21563/TECPEC/runs/z4lekcdz</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shreyas21563/TECPEC/runs/z4lekcdz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7829d02743a0>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project='TECPEC', name='RoBERTa_cat_Utt_Level', config={\n","    'Embedding': 'Sentence-Transformer',\n","    'Level': 'Utterance Level',\n","    'Approach': 'Concat each utterance embedding with the target utterance embedding',\n","    'Epochs': epochs,\n","    'Optimizer': 'AdamW',\n","    'Learning Rate': 1e-6,\n","    'Batch Size': 16\n","})"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T17:53:50.626196Z","iopub.status.busy":"2024-04-22T17:53:50.625789Z","iopub.status.idle":"2024-04-22T18:43:45.850050Z","shell.execute_reply":"2024-04-22T18:43:45.848662Z","shell.execute_reply.started":"2024-04-22T17:53:50.626164Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:36<00:00,  7.88it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Train Loss: 1.6718021756889634, Val Loss: 1.600694219271342\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00      1423\n","         joy       0.10      0.01      0.01      2047\n","        fear       0.03      0.04      0.04       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.44      0.88      0.58      5299\n","    surprise       0.04      0.00      0.00      1656\n","     sadness       0.07      0.06      0.06      1011\n","\n","    accuracy                           0.39     12144\n","   macro avg       0.10      0.14      0.10     12144\n","weighted avg       0.22      0.39      0.26     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00       192\n","         joy       0.00      0.00      0.00       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.43      1.00      0.60       630\n","    surprise       0.00      0.00      0.00       184\n","     sadness       0.00      0.00      0.00       136\n","\n","    accuracy                           0.43      1475\n","   macro avg       0.06      0.14      0.09      1475\n","weighted avg       0.18      0.43      0.26      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:36<00:00,  7.90it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2, Train Loss: 1.5994040923627468, Val Loss: 1.5952196557034728\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00      1423\n","         joy       0.00      0.00      0.00      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.44      1.00      0.61      5299\n","    surprise       0.00      0.00      0.00      1656\n","     sadness       0.00      0.00      0.00      1011\n","\n","    accuracy                           0.44     12144\n","   macro avg       0.06      0.14      0.09     12144\n","weighted avg       0.19      0.44      0.27     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00       192\n","         joy       0.00      0.00      0.00       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.43      1.00      0.60       630\n","    surprise       0.00      0.00      0.00       184\n","     sadness       0.00      0.00      0.00       136\n","\n","    accuracy                           0.43      1475\n","   macro avg       0.06      0.14      0.09      1475\n","weighted avg       0.18      0.43      0.26      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:36<00:00,  7.90it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3, Train Loss: 1.5901452224402246, Val Loss: 1.5770513908837431\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00      1423\n","         joy       0.00      0.00      0.00      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.44      1.00      0.61      5299\n","    surprise       1.00      0.00      0.00      1656\n","     sadness       0.00      0.00      0.00      1011\n","\n","    accuracy                           0.44     12144\n","   macro avg       0.21      0.14      0.09     12144\n","weighted avg       0.33      0.44      0.27     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00       192\n","         joy       0.00      0.00      0.00       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.43      1.00      0.60       630\n","    surprise       0.00      0.00      0.00       184\n","     sadness       0.00      0.00      0.00       136\n","\n","    accuracy                           0.43      1475\n","   macro avg       0.06      0.14      0.09      1475\n","weighted avg       0.18      0.43      0.26      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4, Train Loss: 1.5743744492687883, Val Loss: 1.5562053201019124\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00      1423\n","         joy       0.00      0.00      0.00      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.44      1.00      0.61      5299\n","    surprise       0.69      0.01      0.01      1656\n","     sadness       0.00      0.00      0.00      1011\n","\n","    accuracy                           0.44     12144\n","   macro avg       0.16      0.14      0.09     12144\n","weighted avg       0.28      0.44      0.27     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00       192\n","         joy       0.00      0.00      0.00       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.43      1.00      0.60       630\n","    surprise       0.77      0.05      0.10       184\n","     sadness       0.00      0.00      0.00       136\n","\n","    accuracy                           0.43      1475\n","   macro avg       0.17      0.15      0.10      1475\n","weighted avg       0.28      0.43      0.27      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.92it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5, Train Loss: 1.5511426942935889, Val Loss: 1.537509766317183\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.31      0.00      0.01      1423\n","         joy       0.50      0.00      0.00      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.44      1.00      0.61      5299\n","    surprise       0.58      0.05      0.09      1656\n","     sadness       0.00      0.00      0.00      1011\n","\n","    accuracy                           0.44     12144\n","   macro avg       0.26      0.15      0.10     12144\n","weighted avg       0.39      0.44      0.28     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00       192\n","         joy       0.00      0.00      0.00       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.43      0.99      0.60       630\n","    surprise       0.61      0.14      0.22       184\n","     sadness       0.00      0.00      0.00       136\n","\n","    accuracy                           0.44      1475\n","   macro avg       0.15      0.16      0.12      1475\n","weighted avg       0.26      0.44      0.29      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.92it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6, Train Loss: 1.529186386678844, Val Loss: 1.5169675061779637\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.37      0.01      0.03      1423\n","         joy       0.45      0.01      0.01      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.45      0.98      0.62      5299\n","    surprise       0.50      0.14      0.22      1656\n","     sadness       0.43      0.00      0.01      1011\n","\n","    accuracy                           0.45     12144\n","   macro avg       0.31      0.16      0.13     12144\n","weighted avg       0.42      0.45      0.30     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.44      0.04      0.07       192\n","         joy       0.67      0.01      0.02       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.45      0.95      0.61       630\n","    surprise       0.41      0.26      0.32       184\n","     sadness       0.33      0.03      0.05       136\n","\n","    accuracy                           0.45      1475\n","   macro avg       0.33      0.18      0.15      1475\n","weighted avg       0.45      0.45      0.32      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7, Train Loss: 1.509188142768322, Val Loss: 1.5158832771803743\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.27      0.03      0.05      1423\n","         joy       0.47      0.02      0.03      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.45      0.96      0.62      5299\n","    surprise       0.48      0.18      0.26      1656\n","     sadness       0.43      0.02      0.04      1011\n","\n","    accuracy                           0.45     12144\n","   macro avg       0.30      0.17      0.14     12144\n","weighted avg       0.41      0.45      0.32     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.38      0.06      0.10       192\n","         joy       0.48      0.05      0.09       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.47      0.89      0.62       630\n","    surprise       0.30      0.33      0.31       184\n","     sadness       0.47      0.07      0.12       136\n","\n","    accuracy                           0.44      1475\n","   macro avg       0.30      0.20      0.18      1475\n","weighted avg       0.41      0.44      0.34      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8, Train Loss: 1.4909585403359455, Val Loss: 1.500956178352397\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.36      0.06      0.11      1423\n","         joy       0.50      0.04      0.07      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.46      0.95      0.62      5299\n","    surprise       0.48      0.23      0.31      1656\n","     sadness       0.44      0.04      0.07      1011\n","\n","    accuracy                           0.46     12144\n","   macro avg       0.32      0.19      0.17     12144\n","weighted avg       0.43      0.46      0.34     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.38      0.15      0.22       192\n","         joy       0.49      0.17      0.26       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.48      0.86      0.62       630\n","    surprise       0.39      0.29      0.34       184\n","     sadness       0.38      0.11      0.17       136\n","\n","    accuracy                           0.46      1475\n","   macro avg       0.30      0.23      0.23      1475\n","weighted avg       0.42      0.46      0.39      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.93it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9, Train Loss: 1.4716182733555871, Val Loss: 1.4886454254068353\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.32      0.06      0.11      1423\n","         joy       0.55      0.10      0.16      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.47      0.93      0.63      5299\n","    surprise       0.47      0.25      0.32      1656\n","     sadness       0.43      0.07      0.11      1011\n","\n","    accuracy                           0.47     12144\n","   macro avg       0.32      0.20      0.19     12144\n","weighted avg       0.44      0.47      0.37     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.33      0.17      0.23       192\n","         joy       0.49      0.21      0.30       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.48      0.86      0.62       630\n","    surprise       0.48      0.27      0.35       184\n","     sadness       0.41      0.12      0.19       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.31      0.23      0.24      1475\n","weighted avg       0.43      0.47      0.41      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.92it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10, Train Loss: 1.4616928377013276, Val Loss: 1.4922468604580048\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.36      0.10      0.15      1423\n","         joy       0.49      0.12      0.19      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.48      0.92      0.63      5299\n","    surprise       0.47      0.25      0.33      1656\n","     sadness       0.44      0.09      0.15      1011\n","\n","    accuracy                           0.48     12144\n","   macro avg       0.32      0.21      0.21     12144\n","weighted avg       0.43      0.48      0.38     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.39      0.08      0.14       192\n","         joy       0.48      0.22      0.31       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.49      0.84      0.62       630\n","    surprise       0.40      0.38      0.39       184\n","     sadness       0.31      0.15      0.20       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.30      0.24      0.24      1475\n","weighted avg       0.42      0.47      0.40      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 11, Train Loss: 1.4465552534667556, Val Loss: 1.4871996557840736\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.37      0.10      0.15      1423\n","         joy       0.51      0.14      0.22      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.48      0.91      0.63      5299\n","    surprise       0.48      0.26      0.34      1656\n","     sadness       0.41      0.13      0.20      1011\n","\n","    accuracy                           0.48     12144\n","   macro avg       0.32      0.22      0.22     12144\n","weighted avg       0.44      0.48      0.39     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.35      0.17      0.23       192\n","         joy       0.48      0.25      0.33       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.50      0.79      0.62       630\n","    surprise       0.40      0.37      0.39       184\n","     sadness       0.28      0.19      0.23       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.29      0.25      0.26      1475\n","weighted avg       0.42      0.47      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 12, Train Loss: 1.4318437385464846, Val Loss: 1.4797452444671302\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.36      0.11      0.17      1423\n","         joy       0.47      0.15      0.22      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.49      0.91      0.63      5299\n","    surprise       0.50      0.27      0.35      1656\n","     sadness       0.40      0.13      0.20      1011\n","\n","    accuracy                           0.48     12144\n","   macro avg       0.32      0.22      0.23     12144\n","weighted avg       0.44      0.48      0.40     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.34      0.16      0.22       192\n","         joy       0.47      0.24      0.32       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.49      0.84      0.62       630\n","    surprise       0.48      0.33      0.39       184\n","     sadness       0.37      0.14      0.20       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.31      0.24      0.25      1475\n","weighted avg       0.43      0.47      0.41      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:36<00:00,  7.90it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 13, Train Loss: 1.4191835437053435, Val Loss: 1.4813449100781513\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.38      0.13      0.20      1423\n","         joy       0.48      0.18      0.26      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.49      0.90      0.64      5299\n","    surprise       0.51      0.30      0.37      1656\n","     sadness       0.42      0.15      0.22      1011\n","\n","    accuracy                           0.49     12144\n","   macro avg       0.33      0.24      0.24     12144\n","weighted avg       0.45      0.49      0.41     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.36      0.14      0.20       192\n","         joy       0.45      0.26      0.33       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.50      0.80      0.62       630\n","    surprise       0.44      0.37      0.40       184\n","     sadness       0.28      0.20      0.23       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.29      0.25      0.25      1475\n","weighted avg       0.42      0.47      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 14, Train Loss: 1.4121413984788735, Val Loss: 1.485440561848302\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.36      0.14      0.20      1423\n","         joy       0.49      0.18      0.27      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.50      0.89      0.64      5299\n","    surprise       0.50      0.30      0.38      1656\n","     sadness       0.43      0.17      0.25      1011\n","\n","    accuracy                           0.49     12144\n","   macro avg       0.33      0.24      0.25     12144\n","weighted avg       0.45      0.49      0.42     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.30      0.11      0.16       192\n","         joy       0.43      0.28      0.34       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.51      0.78      0.62       630\n","    surprise       0.41      0.40      0.40       184\n","     sadness       0.30      0.22      0.26       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.28      0.26      0.25      1475\n","weighted avg       0.41      0.47      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 15, Train Loss: 1.3936398898659959, Val Loss: 1.478259458336779\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.39      0.15      0.21      1423\n","         joy       0.50      0.20      0.29      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.50      0.89      0.64      5299\n","    surprise       0.53      0.32      0.40      1656\n","     sadness       0.44      0.20      0.27      1011\n","\n","    accuracy                           0.50     12144\n","   macro avg       0.34      0.25      0.26     12144\n","weighted avg       0.46      0.50      0.43     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.35      0.18      0.24       192\n","         joy       0.46      0.24      0.32       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.49      0.86      0.62       630\n","    surprise       0.51      0.30      0.38       184\n","     sadness       0.43      0.12      0.18       136\n","\n","    accuracy                           0.48      1475\n","   macro avg       0.32      0.24      0.25      1475\n","weighted avg       0.44      0.48      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:36<00:00,  7.90it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 16, Train Loss: 1.3813883192611462, Val Loss: 1.4793699710599837\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.42      0.18      0.26      1423\n","         joy       0.51      0.22      0.31      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.51      0.88      0.65      5299\n","    surprise       0.54      0.33      0.41      1656\n","     sadness       0.45      0.20      0.28      1011\n","\n","    accuracy                           0.51     12144\n","   macro avg       0.35      0.26      0.27     12144\n","weighted avg       0.47      0.51      0.44     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.31      0.20      0.25       192\n","         joy       0.47      0.24      0.32       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.51      0.78      0.62       630\n","    surprise       0.43      0.36      0.39       184\n","     sadness       0.29      0.22      0.25       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.29      0.26      0.26      1475\n","weighted avg       0.42      0.47      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.22it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 17, Train Loss: 1.3718116037616304, Val Loss: 1.484023961328691\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.38      0.18      0.24      1423\n","         joy       0.50      0.22      0.31      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.51      0.88      0.65      5299\n","    surprise       0.54      0.34      0.42      1656\n","     sadness       0.46      0.21      0.29      1011\n","\n","    accuracy                           0.51     12144\n","   macro avg       0.34      0.26      0.27     12144\n","weighted avg       0.47      0.51      0.44     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.31      0.14      0.19       192\n","         joy       0.51      0.23      0.32       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.51      0.81      0.63       630\n","    surprise       0.43      0.40      0.42       184\n","     sadness       0.29      0.22      0.25       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.29      0.26      0.26      1475\n","weighted avg       0.43      0.47      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 18, Train Loss: 1.361909548912752, Val Loss: 1.4945767079630206\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.41      0.20      0.27      1423\n","         joy       0.55      0.24      0.33      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.52      0.88      0.66      5299\n","    surprise       0.55      0.35      0.43      1656\n","     sadness       0.43      0.23      0.30      1011\n","\n","    accuracy                           0.52     12144\n","   macro avg       0.35      0.27      0.28     12144\n","weighted avg       0.48      0.52      0.46     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.27      0.22      0.24       192\n","         joy       0.41      0.30      0.34       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.53      0.73      0.61       630\n","    surprise       0.41      0.43      0.42       184\n","     sadness       0.34      0.17      0.23       136\n","\n","    accuracy                           0.46      1475\n","   macro avg       0.28      0.26      0.26      1475\n","weighted avg       0.41      0.46      0.43      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.92it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 19, Train Loss: 1.3515316337464827, Val Loss: 1.4983473580370668\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.42      0.20      0.27      1423\n","         joy       0.52      0.24      0.33      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.00      0.00      0.00       372\n","     neutral       0.52      0.88      0.66      5299\n","    surprise       0.56      0.36      0.44      1656\n","     sadness       0.47      0.25      0.33      1011\n","\n","    accuracy                           0.52     12144\n","   macro avg       0.36      0.28      0.29     12144\n","weighted avg       0.48      0.52      0.46     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.28      0.23      0.26       192\n","         joy       0.39      0.32      0.35       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.52      0.70      0.60       630\n","    surprise       0.45      0.35      0.39       184\n","     sadness       0.31      0.26      0.28       136\n","\n","    accuracy                           0.45      1475\n","   macro avg       0.28      0.27      0.27      1475\n","weighted avg       0.41      0.45      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.94it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 20, Train Loss: 1.3374424824915698, Val Loss: 1.4890805316227738\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.43      0.22      0.29      1423\n","         joy       0.53      0.26      0.35      2047\n","        fear       1.00      0.00      0.01       336\n","     disgust       1.00      0.00      0.01       372\n","     neutral       0.53      0.87      0.66      5299\n","    surprise       0.57      0.36      0.44      1656\n","     sadness       0.46      0.25      0.32      1011\n","\n","    accuracy                           0.52     12144\n","   macro avg       0.64      0.28      0.30     12144\n","weighted avg       0.54      0.52      0.47     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.29      0.21      0.24       192\n","         joy       0.42      0.28      0.34       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.52      0.76      0.62       630\n","    surprise       0.43      0.36      0.40       184\n","     sadness       0.32      0.21      0.25       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.28      0.26      0.26      1475\n","weighted avg       0.41      0.47      0.43      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.95it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 21, Train Loss: 1.3269000983992112, Val Loss: 1.5107266960605499\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.42      0.24      0.30      1423\n","         joy       0.55      0.27      0.36      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       1.00      0.00      0.01       372\n","     neutral       0.53      0.87      0.66      5299\n","    surprise       0.58      0.36      0.44      1656\n","     sadness       0.48      0.26      0.33      1011\n","\n","    accuracy                           0.52     12144\n","   macro avg       0.51      0.29      0.30     12144\n","weighted avg       0.52      0.52      0.47     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.27      0.22      0.24       192\n","         joy       0.45      0.26      0.33       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.53      0.72      0.61       630\n","    surprise       0.38      0.42      0.40       184\n","     sadness       0.28      0.21      0.24       136\n","\n","    accuracy                           0.45      1475\n","   macro avg       0.27      0.26      0.26      1475\n","weighted avg       0.41      0.45      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.93it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 22, Train Loss: 1.3151847752343682, Val Loss: 1.5020532037622185\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.42      0.24      0.30      1423\n","         joy       0.54      0.27      0.36      2047\n","        fear       0.00      0.00      0.00       336\n","     disgust       0.33      0.00      0.01       372\n","     neutral       0.53      0.87      0.66      5299\n","    surprise       0.58      0.38      0.46      1656\n","     sadness       0.48      0.27      0.34      1011\n","\n","    accuracy                           0.53     12144\n","   macro avg       0.41      0.29      0.30     12144\n","weighted avg       0.50      0.53      0.48     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.30      0.15      0.20       192\n","         joy       0.50      0.22      0.30       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.51      0.81      0.63       630\n","    surprise       0.41      0.43      0.42       184\n","     sadness       0.32      0.18      0.23       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.29      0.26      0.25      1475\n","weighted avg       0.42      0.47      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.92it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 23, Train Loss: 1.3036655624236357, Val Loss: 1.5077380852032733\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.47      0.25      0.32      1423\n","         joy       0.55      0.28      0.37      2047\n","        fear       1.00      0.00      0.01       336\n","     disgust       0.80      0.01      0.02       372\n","     neutral       0.54      0.87      0.67      5299\n","    surprise       0.57      0.38      0.46      1656\n","     sadness       0.47      0.29      0.36      1011\n","\n","    accuracy                           0.53     12144\n","   macro avg       0.63      0.30      0.32     12144\n","weighted avg       0.55      0.53      0.48     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.27      0.19      0.22       192\n","         joy       0.42      0.29      0.34       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.52      0.74      0.61       630\n","    surprise       0.42      0.39      0.41       184\n","     sadness       0.28      0.16      0.21       136\n","\n","    accuracy                           0.46      1475\n","   macro avg       0.27      0.25      0.26      1475\n","weighted avg       0.41      0.46      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.92it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 24, Train Loss: 1.296358489157811, Val Loss: 1.501633325571655\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.45      0.26      0.33      1423\n","         joy       0.54      0.29      0.38      2047\n","        fear       1.00      0.01      0.02       336\n","     disgust       0.62      0.01      0.03       372\n","     neutral       0.54      0.87      0.67      5299\n","    surprise       0.58      0.39      0.47      1656\n","     sadness       0.49      0.28      0.35      1011\n","\n","    accuracy                           0.54     12144\n","   macro avg       0.60      0.30      0.32     12144\n","weighted avg       0.55      0.54      0.49     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.27      0.19      0.22       192\n","         joy       0.42      0.29      0.34       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.51      0.76      0.61       630\n","    surprise       0.45      0.35      0.39       184\n","     sadness       0.28      0.18      0.22       136\n","\n","    accuracy                           0.46      1475\n","   macro avg       0.28      0.25      0.26      1475\n","weighted avg       0.41      0.46      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.91it/s]\n","100%|██████████| 93/93 [00:03<00:00, 23.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 25, Train Loss: 1.2812524717472915, Val Loss: 1.5095000946393577\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.44      0.28      0.34      1423\n","         joy       0.56      0.31      0.40      2047\n","        fear       0.50      0.01      0.01       336\n","     disgust       0.70      0.02      0.04       372\n","     neutral       0.54      0.87      0.67      5299\n","    surprise       0.60      0.40      0.48      1656\n","     sadness       0.49      0.29      0.37      1011\n","\n","    accuracy                           0.54     12144\n","   macro avg       0.55      0.31      0.33     12144\n","weighted avg       0.54      0.54      0.50     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.29      0.21      0.24       192\n","         joy       0.46      0.25      0.32       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.50      0.79      0.62       630\n","    surprise       0.46      0.34      0.39       184\n","     sadness       0.31      0.17      0.22       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.29      0.25      0.26      1475\n","weighted avg       0.42      0.47      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.92it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 26, Train Loss: 1.2740288441988477, Val Loss: 1.5162971865746282\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.45      0.28      0.34      1423\n","         joy       0.57      0.31      0.41      2047\n","        fear       0.50      0.00      0.01       336\n","     disgust       0.43      0.02      0.03       372\n","     neutral       0.55      0.87      0.68      5299\n","    surprise       0.60      0.41      0.48      1656\n","     sadness       0.50      0.31      0.38      1011\n","\n","    accuracy                           0.55     12144\n","   macro avg       0.51      0.31      0.33     12144\n","weighted avg       0.54      0.55      0.50     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.28      0.21      0.24       192\n","         joy       0.41      0.29      0.34       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.51      0.76      0.61       630\n","    surprise       0.47      0.33      0.39       184\n","     sadness       0.30      0.19      0.23       136\n","\n","    accuracy                           0.46      1475\n","   macro avg       0.28      0.25      0.26      1475\n","weighted avg       0.41      0.46      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.92it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 27, Train Loss: 1.2595881293570728, Val Loss: 1.5212213538026298\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.47      0.29      0.36      1423\n","         joy       0.58      0.32      0.41      2047\n","        fear       0.43      0.01      0.02       336\n","     disgust       0.58      0.02      0.04       372\n","     neutral       0.55      0.87      0.68      5299\n","    surprise       0.60      0.42      0.49      1656\n","     sadness       0.51      0.31      0.38      1011\n","\n","    accuracy                           0.55     12144\n","   macro avg       0.53      0.32      0.34     12144\n","weighted avg       0.55      0.55      0.51     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.28      0.19      0.23       192\n","         joy       0.45      0.28      0.34       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.51      0.78      0.62       630\n","    surprise       0.46      0.33      0.38       184\n","     sadness       0.30      0.20      0.24       136\n","\n","    accuracy                           0.47      1475\n","   macro avg       0.28      0.25      0.26      1475\n","weighted avg       0.42      0.47      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.92it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 28, Train Loss: 1.250493832727666, Val Loss: 1.521008312702179\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.47      0.30      0.37      1423\n","         joy       0.59      0.33      0.42      2047\n","        fear       0.50      0.00      0.01       336\n","     disgust       0.53      0.04      0.08       372\n","     neutral       0.56      0.87      0.68      5299\n","    surprise       0.61      0.41      0.49      1656\n","     sadness       0.52      0.33      0.40      1011\n","\n","    accuracy                           0.55     12144\n","   macro avg       0.54      0.33      0.35     12144\n","weighted avg       0.55      0.55      0.51     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.27      0.19      0.22       192\n","         joy       0.40      0.30      0.34       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.51      0.75      0.61       630\n","    surprise       0.46      0.35      0.40       184\n","     sadness       0.31      0.19      0.24       136\n","\n","    accuracy                           0.46      1475\n","   macro avg       0.28      0.25      0.26      1475\n","weighted avg       0.41      0.46      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.93it/s]\n","100%|██████████| 93/93 [00:03<00:00, 24.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 29, Train Loss: 1.233226150627664, Val Loss: 1.5538828385773527\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.48      0.31      0.38      1423\n","         joy       0.59      0.34      0.43      2047\n","        fear       0.62      0.01      0.03       336\n","     disgust       0.70      0.07      0.13       372\n","     neutral       0.57      0.87      0.69      5299\n","    surprise       0.62      0.43      0.51      1656\n","     sadness       0.51      0.33      0.40      1011\n","\n","    accuracy                           0.56     12144\n","   macro avg       0.58      0.34      0.37     12144\n","weighted avg       0.57      0.56      0.52     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.28      0.22      0.25       192\n","         joy       0.39      0.31      0.34       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.52      0.69      0.60       630\n","    surprise       0.42      0.33      0.37       184\n","     sadness       0.27      0.26      0.26       136\n","\n","    accuracy                           0.44      1475\n","   macro avg       0.27      0.26      0.26      1475\n","weighted avg       0.40      0.44      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 759/759 [01:35<00:00,  7.93it/s]\n","100%|██████████| 93/93 [00:03<00:00, 23.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 30, Train Loss: 1.2320747579667566, Val Loss: 1.5405513323763365\n","Train Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.48      0.32      0.38      1423\n","         joy       0.59      0.34      0.43      2047\n","        fear       0.67      0.01      0.02       336\n","     disgust       0.53      0.05      0.09       372\n","     neutral       0.56      0.87      0.68      5299\n","    surprise       0.61      0.43      0.50      1656\n","     sadness       0.52      0.33      0.40      1011\n","\n","    accuracy                           0.56     12144\n","   macro avg       0.57      0.33      0.36     12144\n","weighted avg       0.56      0.56      0.52     12144\n","\n","Val Report: \n","              precision    recall  f1-score   support\n","\n","       anger       0.27      0.21      0.24       192\n","         joy       0.41      0.30      0.35       254\n","        fear       0.00      0.00      0.00        37\n","     disgust       0.00      0.00      0.00        42\n","     neutral       0.52      0.73      0.61       630\n","    surprise       0.42      0.36      0.39       184\n","     sadness       0.31      0.19      0.24       136\n","\n","    accuracy                           0.46      1475\n","   macro avg       0.27      0.26      0.26      1475\n","weighted avg       0.41      0.46      0.42      1475\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for epoch in range(epochs):\n","    model.train()\n","    train_pred, train_true, train_loss = [], [], 0.0\n","    for batch in tqdm(train_loader):\n","        optimizer.zero_grad()\n","        context_embeddings_cat, target_embedding, emotions, attention_mask = batch['context_embeddings_cat'].to(device), batch['target_embedding'].to(device), batch['emotion'].to(device), batch['attention_mask'].to(device)\n","        outputs = model(context_embeds=context_embeddings_cat, target_embeds=target_embedding, attention_mask=attention_mask, labels=emotions)\n","        loss = outputs['loss']\n","        loss.backward()\n","        optimizer.step()\n","        train_pred.extend(torch.argmax(outputs['logits'], 1).tolist())\n","        train_true.extend(emotions.tolist())\n","        train_loss += loss.item()\n","    train_loss /= len(train_loader) \n","    model.eval()\n","    val_pred, val_true, val_loss = [], [], 0.0\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader):\n","            context_embeddings_cat, target_embedding, emotions, attention_mask = batch['context_embeddings_cat'].to(device), batch['target_embedding'].to(device), batch['emotion'].to(device), batch['attention_mask'].to(device)\n","            outputs = model(context_embeds=context_embeddings_cat, target_embeds=target_embedding, attention_mask=attention_mask, labels=emotions)\n","            loss = outputs['loss']\n","            val_pred.extend(torch.argmax(outputs['logits'], 1).tolist())\n","            val_true.extend(emotions.tolist())\n","            val_loss += loss.item()\n","            \n","    val_loss /= len(val_loader)\n","    train_report = classification_report(train_true, train_pred, target_names=emotion2int.keys(), zero_division=0)\n","    val_report = classification_report(val_true, val_pred, target_names=emotion2int.keys(), zero_division=0)\n","\n","    train_report_dict = classification_report(train_true, train_pred, target_names=emotion2int.keys(), output_dict=True, zero_division=0)\n","    val_report_dict = classification_report(val_true, val_pred, target_names=emotion2int.keys(), output_dict=True, zero_division=0)\n","    wandb.log({\n","        'train_loss': train_loss,\n","        'val_loss': val_loss,\n","        'train_accuracy': train_report_dict['accuracy'],\n","        'val_accuracy': val_report_dict['accuracy'],\n","        'Macro train_f1': train_report_dict['macro avg']['f1-score'],\n","        'Macro val_f1': val_report_dict['macro avg']['f1-score'],\n","        'Weighted train_f1': train_report_dict['weighted avg']['f1-score'],\n","        'Weighted val_f1': val_report_dict['weighted avg']['f1-score'],\n","    })\n","    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n","    print(f\"Train Report: \\n{train_report}\")\n","    print(f\"Val Report: \\n{val_report}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for epoch in range(epochs):\n","    model.train()\n","    train_pred, train_true, train_loss = [], [], 0.0\n","    for batch in tqdm(train_loader):\n","        optimizer.zero_grad()\n","        context_embeddings_cat, target_embedding, emotions, attention_mask = batch['context_embeddings'].to(device), batch['target_embedding'].to(device), batch['emotion'].to(device), batch['attention_mask'].to(device)\n","        outputs = model(context_embeds=context_embeddings_cat, target_embeds=target_embedding, attention_mask=attention_mask, labels=emotions)\n","        loss = outputs['loss']\n","        loss.backward()\n","        optimizer.step()\n","        train_pred.extend(torch.argmax(outputs['logits'], 1).tolist())\n","        train_true.extend(emotions.tolist())\n","        train_loss += loss.item()\n","    train_loss /= len(train_loader) \n","    model.eval()\n","    val_pred, val_true, val_loss = [], [], 0.0\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader):\n","            context_embeddings_cat, target_embedding, emotions, attention_mask = batch['context_embeddings'].to(device), batch['target_embedding'].to(device), batch['emotion'].to(device), batch['attention_mask'].to(device)\n","            outputs = model(context_embeds=context_embeddings_cat, target_embeds=target_embedding, attention_mask=attention_mask, labels=emotions)\n","            loss = outputs['loss']\n","            val_pred.extend(torch.argmax(outputs['logits'], 1).tolist())\n","            val_true.extend(emotions.tolist())\n","            val_loss += loss.item()\n","            \n","    val_loss /= len(val_loader)\n","    train_report = classification_report(train_true, train_pred, target_names=emotion2int.keys(), zero_division=0)\n","    val_report = classification_report(val_true, val_pred, target_names=emotion2int.keys(), zero_division=0)\n","\n","    train_report_dict = classification_report(train_true, train_pred, target_names=emotion2int.keys(), output_dict=True, zero_division=0)\n","    val_report_dict = classification_report(val_true, val_pred, target_names=emotion2int.keys(), output_dict=True, zero_division=0)\n","    wandb.log({\n","        'train_loss': train_loss,\n","        'val_loss': val_loss,\n","        'train_accuracy': train_report_dict['accuracy'],\n","        'val_accuracy': val_report_dict['accuracy'],\n","        'Macro train_f1': train_report_dict['macro avg']['f1-score'],\n","        'Macro val_f1': val_report_dict['macro avg']['f1-score'],\n","        'Weighted train_f1': train_report_dict['weighted avg']['f1-score'],\n","        'Weighted val_f1': val_report_dict['weighted avg']['f1-score'],\n","    })\n","    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n","    print(f\"Train Report: \\n{train_report}\")\n","    print(f\"Val Report: \\n{val_report}\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T18:45:35.888775Z","iopub.status.busy":"2024-04-22T18:45:35.887916Z","iopub.status.idle":"2024-04-22T18:46:10.538269Z","shell.execute_reply":"2024-04-22T18:46:10.537214Z","shell.execute_reply.started":"2024-04-22T18:45:35.888736Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Macro train_f1</td><td>▁▁▁▁▁▂▂▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Macro val_f1</td><td>▁▁▁▂▂▄▄▆▇▇▇▇▇▇▇██████▇▇█▇█████</td></tr><tr><td>Weighted train_f1</td><td>▁▁▁▁▁▂▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>Weighted val_f1</td><td>▁▁▁▂▂▄▄▇▇▇████████████████████</td></tr><tr><td>train_accuracy</td><td>▁▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▂▃▄▃▆▇▇▆▇▇▆█▇▇▆▅▆▅▇▅▆▆▆▆▅▃▅</td></tr><tr><td>val_loss</td><td>██▇▅▄▃▃▂▂▂▂▁▁▁▁▁▁▂▂▂▃▂▃▂▃▃▃▃▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Macro train_f1</td><td>0.35964</td></tr><tr><td>Macro val_f1</td><td>0.25937</td></tr><tr><td>Weighted train_f1</td><td>0.52056</td></tr><tr><td>Weighted val_f1</td><td>0.42044</td></tr><tr><td>train_accuracy</td><td>0.56036</td></tr><tr><td>train_loss</td><td>1.23207</td></tr><tr><td>val_accuracy</td><td>0.45559</td></tr><tr><td>val_loss</td><td>1.54055</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">RoBERTa_cat_Utt_Level</strong> at: <a href='https://wandb.ai/shreyas21563/TECPEC/runs/z4lekcdz' target=\"_blank\">https://wandb.ai/shreyas21563/TECPEC/runs/z4lekcdz</a><br/> View project at: <a href='https://wandb.ai/shreyas21563/TECPEC' target=\"_blank\">https://wandb.ai/shreyas21563/TECPEC</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240422_175330-z4lekcdz/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T18:46:34.668548Z","iopub.status.busy":"2024-04-22T18:46:34.667664Z","iopub.status.idle":"2024-04-22T18:46:35.561477Z","shell.execute_reply":"2024-04-22T18:46:35.560275Z","shell.execute_reply.started":"2024-04-22T18:46:34.668513Z"},"trusted":true},"outputs":[],"source":["torch.save(model, '/kaggle/working/RoBERTa_cat_Utt_Level.pth')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4785760,"sourceId":8195327,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
